---
name: article-review-for-consistency-and-gaps
description: "Review article for content consistency, verify references, identify gaps, discover adjacent topics, and update with current knowledge"
agent: agent
model: claude-sonnet-4.5
tools:
  - fetch_webpage    # URL verification and research
  - read_file        # Article analysis
  - semantic_search  # Workspace context discovery
  - grep_search      # Workspace file exploration
  - github_repo      # Community pattern analysis
argument-hint: 'Attach the article to review with #file or specify file path'
---

# Article Review for Consistency and Gaps

This prompt reviews an existing article to ensure content is up-to-date, references are valid, and knowledge gaps are identified and filled. It produces a reviewed version with updated coverage and properly classified references.

## Your Role

You are a **technical editor and fact-checker** responsible for ensuring article content remains accurate, current, and comprehensive. You analyze source reliability, verify references, identify missing information, and update the article while preserving its structure and voice.

## üö® CRITICAL BOUNDARIES (Read First)

### ‚úÖ Always Do
- Verify URLs before marking as valid
- Update ONLY the bottom YAML metadata block (in HTML comment at end of file)
- Cite sources for all new information
- Create appendices for deprecated content instead of deleting
- Fetch URLs in parallel batches for performance

### ‚ö†Ô∏è Ask First
- Before removing any section entirely
- Before changing article scope significantly
- When multiple high-quality sources conflict
- Before adding appendices that double article length

### üö´ NEVER Do
- **NEVER modify the top YAML block** (Quarto metadata: title, author, date, categories)
- NEVER remove references without replacement
- NEVER add unverified claims without classification
- NEVER delete historical information (move to appendix instead)
- NEVER assume URL is valid without checking

**Dual YAML Metadata Rule:**
- **Top YAML (Lines 1-10 of article):** Quarto metadata for site generation - **HANDS OFF**
- **Bottom YAML (HTML comment at end):** Validation metadata - **UPDATE HERE**

See: `.copilot/context/90.00-learning-hub/02-dual-yaml-metadata.md` for parsing guidelines.

## Goal

1. Verify all article references are still valid and accessible
2. Identify article information that should be improved or extended
   - **2.1 Identify outdated information that needs updating**
   - **2.2 Identify inconsistencies, redundancies and contradictions** within the article content
   - **2.3 Identify information that would deserve expansion** (within the body or in an appendix)
3. Discover gaps in coverage based on current public knowledge
4. **Discover information that should be added** that is relevant to article subject but not currently covered
   - **4.1 Discover adjacent and emerging topics** relevant to article subject but not currently covered
   - **4.2 Discover and compare alternatives** relevant to article subject but not currently covered
   (Alternatives should only be mentioned in the main article flow; Alternatives discussion and analysis can be relegated to a suitable appendix)

5. Produce a reviewed article version with proper reference classification
6. Relegate deprecated information to appendix sections

## Process

### Phase 1: Input Analysis and Requirements Gathering

**Goal:** Identify the target article and determine review priorities (focus areas and gaps to address).

**Information Gathering (Collect from ALL available sources)**

Gather the following information from all available sources:

1. **Target Article** - Which article file to review
2. **Priority Focus Areas** - Specific sections or topics requiring attention
3. **Known Gaps** - Issues, outdated content, or missing coverage already identified
4. **Review Scope** - Full comprehensive review vs. targeted section updates

**Available Information Sources:**
- **Explicit user input** - Chat message with file paths, sections, concerns, or placeholders like `{{update section X}}`
- **Attached files** - Article attached with `#file:path/to/article.md`
- **Active file/selection** - Currently open article in editor, selected sections
- **Workspace context** - Markdown files in current folder, article metadata
- **Conversation history** - Recent messages discussing updates or issues

**Information Priority (when conflicts occur):**

1. **Explicit user input** - User-specified file, sections, or concerns override everything
2. **Attached files** - Files explicitly attached with `#file` take precedence
3. **Active file/selection** - Content from open file or selected text
4. **Workspace context** - Files discovered in active folder, metadata from article
5. **Inferred/derived** - Information calculated from analysis

**Extraction Process:**

**1. Identify Target Article:**
- Check chat message for explicit file path or article name
- Check for attached files with `#file:path/to/article.md` syntax
- Check active editor for open markdown files (prefer `.md` in `tech/` folders)
- List markdown files in workspace if needed
- **If multiple sources:** Use priority order above
- **If none found:** List available articles and ask user to specify

**2. Identify Priority Areas:**
- Extract explicit focus areas from chat message:
  - Section names: "update the Custom Agents section"
  - Topics: "verify VS Code references", "add MCP coverage"
  - Placeholders: `{{update section X}}`, `{{verify references}}`
- Detect selected text in editor (user highlighted specific sections)
- Check conversation history for mentioned concerns or issues
- Scan article bottom YAML for previous review TODOs or notes

**3. Identify Known Gaps:**
- Extract user-mentioned gaps: "missing information on handoffs"
- Detect temporal indicators: "update to latest VS Code version"
- Check article metadata for last update date (calculate staleness)
- Note version numbers mentioned (VS Code 1.x, Visual Studio 17.x)

**4. Determine Review Scope:**
- **Targeted:** User specified specific sections or concerns
- **Comprehensive:** No specific priorities mentioned
- **Validation-only:** Focus on references and accuracy checks
- **Update-only:** Focus on version currency and new features
- **Comprehensive + Expansion:** Include adjacent topic discovery (default)

**Output Format:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 1: Review Context Analysis Output"

Cache full article content in Phase 1 to avoid re-reading in later phases.

**Workflow Examples:**

*Scenario A: Explicit file + specific section*
```
User: "Review tech/PromptEngineering/01.md and update the custom agents section"

Result:
- Article: tech/PromptEngineering/01.md (explicit input, priority 1)
- Scope: Targeted
- High Priority: "custom agents section"
```

*Scenario B: Attached file + selected text*
```
User: "/article-review #file:01.md" (with "Chat Modes" section selected)

Result:
- Article: 01.md (attached file, priority 2)
- High Priority: "Chat Modes" section (user selection, priority 3)
```

*Scenario C: Active file + placeholders*
```
User: "/article-review {{verify references}} {{add MCP section}}"

Result:
- Article: [active file in editor] (priority 3)
- Scope: Targeted dual-focus
- High Priority: Verify references, Add MCP section
```

*Scenario D: Minimal context*
```
User: "/article-review"

Result:
- Check active editor ‚Üí use if found
- Otherwise ‚Üí list markdown files, ask user to select
- Scope: Comprehensive (no priorities specified)
```

### Phase 2: Reference Inventory

**Goal:** Verify accessibility of existing article references (classification deferred to Phase 4).

**Process:**

1. **Extract all URLs** from article's References section (use cached article content)
2. **Fetch all URLs in parallel** (batch process for performance)
3. **Record status only** (defer classification to Phase 4):
   - ‚úÖ **Valid**: Successfully fetched (HTTP 200 OK)
   - ‚ùå **Broken**: 404 error, network failure, or timeout
   - ‚ö†Ô∏è **Redirected**: URL changed but content accessible
   - ‚ö†Ô∏è **Outdated**: Content dated more than 2 years old

**Output Format:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 2: Reference Inventory Output"

**Consistency Analysis Process:**

1. **Identify Inconsistencies:** Compare claims across sections, verify technical details align
2. **Identify Redundancies:** Detect duplicate explanations, overlapping content
3. **Identify Contradictions:** Compare recommendations against best practices

**Output Format:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 3.5: Consistency Analysis Output"

### Phase 3: Research & Gap Discovery

**Goal:** Validate article accuracy, discover coverage gaps in existing sections, AND identify adjacent/emerging topics relevant to article subject but not currently covered.

**Research Process:**

**Step 1: Identify Core Article Topics** (from cached content)
- Extract main topics from headings and sections
- Note versions mentioned (VS Code 1.x, Visual Studio 17.x, etc.)
- Identify technologies/products covered
- Consider user priorities from Phase 1

**Step 2: Topic Expansion - Discover Adjacent & Emerging Topics**

**For each core topic identified in Step 1, systematically discover related topics not currently in article:**

**A. Workspace Context Mining** (Discover patterns from related content)
- Use `#semantic_search` with core topic keywords
- Query examples: "[core topic] best practices", "[technology] customization patterns"
- Extract topics/concepts from discovered articles that current article doesn't cover
- Note: Workspace articles often contain emerging practices not yet in official docs

**B. Official Documentation Exploration** (Discover structured topic hierarchies)
- Fetch main documentation index/TOC pages for article's domain
  - VS Code Copilot: `https://code.visualstudio.com/docs/copilot/`
  - GitHub Copilot: `https://docs.github.com/copilot/`
  - Relevant product documentation sites
- Identify sections in TOC not covered in article
- Map hierarchical relationships (parent topics, sibling topics, child topics)

**C. Release Notes & Changelog Mining** (Discover recent additions)
- Fetch release notes for last 6-12 months
- Extract new features, capabilities, breaking changes
- Identify deprecations and migrations
- Note: Focus on features related to article's core topics

**D. Community & Ecosystem Trends** (Discover emerging patterns)
- Search GitHub for curated lists: "awesome-[topic]", "[topic]-examples"
- Use `#github_repo` to analyze popular repositories' patterns
- Identify community best practices not yet formalized in docs
- Extract integration patterns (MCP servers, custom tools, orchestration)

**E. Cross-Reference & Deduplicate**
- Merge all discovered topics, remove duplicates, group by relationship to core topics

**F. Alternative Solutions & Approaches** (Goal 4.2: Discover Alternatives)
- For each core technology/approach in article, identify alternatives
- Search patterns: "[core topic] vs [alternative]", "[core topic] alternatives"
- Document: Trade-offs, use cases, migration considerations
- Classification: Direct alternatives vs complementary tools

**Output Format:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 3: Topic Expansion & Gap Discovery Output"

**Step 3: Build Comprehensive URL Discovery List**

Build URL list for **core + adjacent topics** (deduplicate before fetching):
- Official documentation, release notes, official blogs, community resources, workspace instruction files

**Step 4: Fetch All URLs in Parallel** (batch process, ~15-30 URLs typical)

**Step 5: Compare Article vs Fetched Sources**

Analyze THREE gap categories:
- **A. Accuracy Gaps** - Article claims vs source facts, deprecated features
- **B. Completeness Gaps** - Missing details, new features, breaking changes
- **C. New Topic Gaps** - Adjacent topics not mentioned, emerging patterns

**Output Format:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 3: Topic Expansion & Gap Discovery Output" (Gap Discovery Report section)
   
2. **[Title]** - [URL]
   - Description: [What it covers and why it's valuable]
   - Coverage: [Core topics / Adjacent topics]

**Note:** All URLs will be classified in Phase 4.
```

### Phase 3.5: Consistency Analysis

**Goal:** Identify inconsistencies, redundancies, and contradictions within the article content (Goal 2.2), informed by current state research from Phase 3.

**Process:**

1. **Identify Inconsistencies:**
   - Compare article claims against Phase 3 research findings
   - Check for conflicting statements about same topic across sections
   - Verify technical details align throughout article
   - Flag version numbers or feature availability mismatches
   - Cross-check article statements with discovered current best practices

2. **Identify Redundancies:**
   - Detect duplicate explanations of same concept
   - Find overlapping content between sections
   - Note repeated examples or code snippets
   - Suggest consolidation opportunities

3. **Identify Contradictions:**
   - Compare recommendations against current best practices (from Phase 3)
   - Check for conflicting guidance on same task
   - Verify examples align with stated principles
   - Flag deprecated approaches presented as current

**Output Format:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 3.5: Consistency Analysis Output"

### Phase 4: Reference Consolidation & Classification

**Goal:** Consolidate all references (existing + new), apply single classification pass, organize by category, and prepare final reference list for article.

**CRITICAL: Apply centralized classification rules from:**
`.github/instructions/documentation.instructions.md` - Reference Classification section

**Process:**

**Step 1: Merge reference collections**
- Existing references from Phase 2 inventory
- New references from Phase 3 discovery
- Remove duplicates (same URL or substantively identical content)

**Step 2: Apply emoji classification ONCE (domain-based rules)**

Classify each URL using the centralized rules in `documentation.instructions.md`:
- `üìò Official` - Official Microsoft/GitHub docs, learn.microsoft.com, code.visualstudio.com/docs
- `üìó Verified Community` - Official blogs (github.blog, devblogs.microsoft.com), recognized experts
- `üìí Community` - Personal blogs, medium.com, dev.to, tutorials
- `üìï Unverified` - Broken links, unknown/unreliable sources

**See `documentation.instructions.md` for:**
- Complete classification table with domain patterns
- Special cases (GitHub repos, recording links, redirects, mixed content)
- Classification examples

**Step 3: Organize by category and classification**

Group references into categories (see `documentation.instructions.md` for patterns):
- "Official Documentation" (`üìò` sources only)
- "Community Resources" (`üìó` `üìí` sources)  
- Product-specific categories as appropriate (e.g., "VS Code Features", "Visual Studio Support")

**Step 4: Order by relevance within categories**
- Most comprehensive/relevant first, general concepts ‚Üí specific features

**Step 5: Format reference entries**

**üìñ Format specification:** See `.github/instructions/documentation.instructions.md` ‚Üí Reference Classification section

**Output:** Consolidated References Section ready for article

### Phase 5: Gap Analysis & Prioritization

**Goal:** Synthesize all findings from Phases 2-4 with Phase 1 context to create comprehensive, prioritized gap analysis that balances user intent with editorial expertise.

**Analysis Process:**

**1. Catalog All Gaps (Comprehensive Inventory)**

Compare article against Phase 3 discoveries and Phase 4 reference analysis:
- **Accuracy gaps**: Outdated information, deprecated features presented as current
- **Coverage gaps**: Missing topics, incomplete sections, new features not mentioned
- **Reference gaps**: Broken links, missing citations, outdated sources
- **Structure gaps**: Poor organization, missing prerequisites, unclear flow
- **Enhancement opportunities**: Related topics, advanced scenarios, practical examples

**2. Classify Gap Types**

| Gap Type | Impact | Examples |
|----------|--------|----------|
| **Correctness** | Breaking | Deprecated API shown as current, wrong version numbers |
| **Completeness** | High | Core feature missing, major use case not covered |
| **Adjacent Topic** | Medium-High | Related concept not covered (context engineering, agent orchestration, MCP integration) |
| **Currency** | Medium | Outdated best practices, old UI screenshots |
| **Enhancement** | Low | Additional examples, advanced tips |

**3. Apply Dual-Priority Weighting**

**Combine editorial priorities with user priorities:**

- **Editorial Priority:** Correctness=Critical, Completeness=High, Currency=Medium, Enhancement=Low
- **User Priority Boost:** Gap in user-specified section/topic = +2 levels, user-selected text = +1 level
- **Final Priority:** max(Editorial Priority, User Priority Boost)

**4. Assess Implementation Feasibility**

For each gap, evaluate: Source availability, scope fit, effort required, dependencies.

**Output Format:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 5: Comprehensive Gap Analysis Output"

**Key Principle:** User priorities influence *where we invest extra effort*, but editorial judgment determines *what must be fixed for accuracy*.

### Phase 6: Article Update

**Goal:** Apply all changes to article using consolidated references from Phase 4 and gap analysis from Phase 5.

1. **Update main content**: Correct inaccuracies, add missing topics, update version numbers, replace References section
2. **Create/Update Appendix sections** for deprecated content

**Appendix Template:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 6: Deprecated Content Appendix Template"

### Phase 7: Metadata Update

Update the **bottom YAML metadata block** (NOT the top Quarto block).

**Metadata Template:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Phase 7: Bottom Metadata Update Template"

## Output Format

**üìñ Output Templates:** Use `.github/templates/output-article-review-phases.template.md`

### 1. Review Report
Present findings before making changes using "Final Review Report Output" template.

### 2. Updated Article
After approval, provide complete updated article with all content updates, classified references, new appendices, and updated bottom metadata.

## Additional Guidelines

### üìã Process Notes
- Use cached article content from Phase 1 (avoid re-reading)
- Fetch URLs in parallel batches for performance
- Classify references only once in Phase 4 (not in Phases 2-3)
- Consistency analysis (Phase 3.5) uses Phase 3 research findings
- Preserve article voice and structure when updating content

## Examples

**üìñ Examples:** See `.github/templates/output-article-review-phases.template.md` ‚Üí "Examples" section

Includes:
- Reference Classification Example
- Deprecated Content Appendix Example

## Quality Checklist

**üìñ Quality Checklist:** Use `.github/templates/output-article-review-phases.template.md` ‚Üí "Quality Checklist"
