---
title: "Appendix 02: Anthropic Claude Prompting Guide Analysis"
author: "Dario Airoldi"
date: "2026-01-20"
categories: [tech, prompt-engineering, anthropic, claude, extended-thinking]
description: "Deep analysis of Anthropic's official prompting guides for Claude Sonnet 4 and Extended Thinking models with extracted techniques and examples"
guide_version:
  url: "https://platform.claude.com/docs/en/docs/build-with-claude/prompt-engineering/overview"
  last_verified: "2026-01-20"
  additional_sources:
    - "https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips"
    - "https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-of-thought"
    - "https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct"
---

# Appendix 02: Anthropic Claude Prompting Guide Analysis

This appendix provides a <mark>comprehensive analysis</mark> of Anthropic's official prompting documentation, extracting key techniques, patterns, and recommendations for **Claude Sonnet 4** and **Extended Thinking** models.

> **Guide Version:** This analysis is based on Anthropic documentation as of **2026-01-20**. Official guides may have been updated since this analysis. Always verify with the [official documentation](https://platform.claude.com/docs/en/docs/build-with-claude/prompt-engineering/overview).

## Table of Contents

- [üìä Model Overview](#-model-overview)
- [üéØ The Golden Rule of Clarity](#-the-golden-rule-of-clarity)
- [üìê Recommended Technique Order](#-recommended-technique-order)
- [üè∑Ô∏è XML Tags for Structure](#Ô∏è-xml-tags-for-structure)
- [üí≠ Chain of Thought Prompting](#-chain-of-thought-prompting)
- [üß† Extended Thinking Mode](#-extended-thinking-mode)
- [üìö Multishot Prompting](#-multishot-prompting)
- [üë§ System Prompts and Roles](#-system-prompts-and-roles)
- [üìù Long Context Tips](#-long-context-tips)
- [‚úÇÔ∏è Prefilling Claude's Response](#Ô∏è-prefilling-claudes-response)
- [üîó Chain Complex Prompts](#-chain-complex-prompts)
- [üîß Practical Examples](#-practical-examples)
- [‚ö†Ô∏è Common Pitfalls](#Ô∏è-common-pitfalls)
- [üìö References](#-references)

# üìä Model Overview

## Claude Model Family

| Model | Best For | Context Window | Key Characteristic |
|-------|----------|----------------|-------------------|
| **Claude Sonnet 4** | Balanced tasks, coding, analysis | 200K tokens | Fast, capable, cost-effective |
| **Claude Opus 4** | Complex reasoning, nuanced writing | 200K tokens | Highest capability |
| **Claude with Extended Thinking** | STEM, complex problems | 200K tokens | Internal reasoning before response |

## Core Philosophy

Anthropic's prompting guidance centers on one key insight:

> <mark>**"Think of Claude as a brilliant but very new employee (with amnesia) who needs explicit instructions."**</mark>

Claude doesn't have context on your norms, styles, guidelines, or preferred ways of working. The more precisely you explain what you want, the better Claude's response will be.

## Prerequisites Before Prompting

Before starting prompt engineering, Anthropic recommends:

1. ‚úÖ **Clear success criteria** defined for your use case
2. ‚úÖ **Empirical testing** methods established
3. ‚úÖ **First draft prompt** ready to improve

# üéØ The Golden Rule of Clarity

> <mark>**Show your prompt to a colleague, ideally someone who has minimal context on the task, and ask them to follow the instructions. If they're confused, Claude will likely be too.**</mark>

## How to Be Clear, Contextual, and Specific

### 1. Provide Contextual Information

Give Claude the context it needs to understand the task:

| Context Type | Example |
|--------------|---------|
| **Purpose** | "This output will be used for a customer-facing FAQ" |
| **Audience** | "The reader is a senior developer familiar with TypeScript" |
| **Workflow position** | "This is step 2 of a 4-step review process" |
| **Success criteria** | "A successful response includes code examples and error handling" |

### 2. Be Specific About Requirements

‚ùå **Vague:** "Analyze this code"

‚úÖ **Specific:** "Analyze this code for:
- Security vulnerabilities (especially SQL injection)
- Performance bottlenecks
- Violations of our coding standards
Output a numbered list with severity ratings."

### 3. Use Sequential Steps

Provide instructions as numbered steps:

```markdown
1. Read the customer complaint
2. Identify the main issue category (billing, technical, shipping)
3. Extract the customer's emotional tone
4. Draft a response that addresses the issue
5. Include a resolution offer if appropriate
```

# üìê Recommended Technique Order

Anthropic organizes prompting techniques from <mark>**most broadly effective to most specialized**</mark>. Try them in this order:

| Priority | Technique | When to Use |
|----------|-----------|-------------|
| 1 | **Prompt Generator** | Starting point for new prompts |
| 2 | **Be Clear and Direct** | Always (foundation of all prompts) |
| 3 | **Use Examples (Multishot)** | When format/style matters |
| 4 | **Let Claude Think (CoT)** | Complex reasoning tasks |
| 5 | **Use XML Tags** | Structured inputs/outputs |
| 6 | **Give Claude a Role** | Persona-specific behavior |
| 7 | **Prefill Claude's Response** | Control output format |
| 8 | **Chain Complex Prompts** | Multi-step workflows |
| 9 | **Long Context Tips** | Large document processing |

# üè∑Ô∏è XML Tags for Structure

Claude responds exceptionally well to <mark>**XML tags**</mark> for organizing prompts and defining clear boundaries.

## Why XML Works Well

- Creates unambiguous section boundaries
- Prevents prompt injection from user content
- Makes parsing of outputs straightforward
- Allows metadata via attributes

## Basic Structure

```xml
<role>
You are a technical documentation specialist reviewing API docs.
</role>

<context>
The API serves a financial services application with strict compliance requirements.
</context>

<task>
Review the following API documentation for completeness.
</task>

<document>
{{user_provided_document}}
</document>

<output_format>
Return a JSON object with:
- completeness_score (0-100)
- missing_sections (array)
- recommendations (array)
</output_format>
```

## Common Tag Patterns

| Tag | Purpose | Example Use |
|-----|---------|-------------|
| `<role>` | Define persona/expertise | `<role>You are a senior security auditor.</role>` |
| `<context>` | Background information | `<context>This is a healthcare application.</context>` |
| `<task>` | Specific instruction | `<task>Identify HIPAA compliance issues.</task>` |
| `<document>` | User-provided content | `<document>{{file_content}}</document>` |
| `<examples>` | Few-shot examples | Wrap input/output pairs |
| `<thinking>` | Request reasoning output | `<thinking>[Claude's reasoning]</thinking>` |
| `<answer>` | Final response section | Separate from thinking |
| `<constraints>` | Rules and limitations | `<constraints>Max 500 words.</constraints>` |

## Nested Structure Example

```xml
<task>
Analyze customer feedback and generate improvement recommendations.
</task>

<feedback_data>
  <feedback id="1" date="2026-01-15">
    Great product, but shipping was slow.
  </feedback>
  <feedback id="2" date="2026-01-16">
    Love the quality! Would buy again.
  </feedback>
  <feedback id="3" date="2026-01-17">
    Customer service was unhelpful with my return.
  </feedback>
</feedback_data>

<output_format>
<analysis>
  <theme name="[theme]">
    <frequency>[count]</frequency>
    <sentiment>[positive/negative/neutral]</sentiment>
    <recommendation>[action item]</recommendation>
  </theme>
</analysis>
</output_format>
```

# üí≠ Chain of Thought Prompting

For complex tasks, <mark>**letting Claude think step-by-step**</mark> dramatically improves performance.

## Benefits of CoT

| Benefit | Description |
|---------|-------------|
| **Accuracy** | Reduces errors in math, logic, analysis |
| **Coherence** | Leads to more organized responses |
| **Debugging** | Reveals where prompts may be unclear |

## When to Use (and Not Use)

‚úÖ **Use CoT for:** Tasks a human would need to think through‚Äîcomplex math, multi-step analysis, writing complex documents, decisions with many factors.

‚ùå **Avoid CoT for:** Simple tasks where it adds unnecessary latency.

## Three Levels of CoT

### Level 1: Basic (Minimal Guidance)

```markdown
Think step-by-step about this problem:
{{problem}}
```

**Limitation:** Lacks guidance on HOW to think.

### Level 2: Guided (Structured Steps)

```markdown
Analyze this code for security vulnerabilities.

Think through:
1. Input validation issues
2. Authentication weaknesses  
3. Data exposure risks
4. Injection vulnerabilities

Then provide your findings.
```

**Benefit:** Directs Claude's reasoning process.

### Level 3: Structured (Separated Output)

```markdown
Analyze this financial report for investment risks.

<thinking>
[Your step-by-step analysis here]
</thinking>

<answer>
[Your final recommendation here]
</answer>
```

**Benefit:** Easy to parse and separate reasoning from conclusions.

## Complete CoT Example

```xml
<task>
Draft a personalized donor thank-you email.
</task>

<donor_info>
Name: Sarah Chen
Donation: $500
History: 3rd year donor, total $1,200
Cause: Education programs
</donor_info>

<instructions>
Think through:
1. What makes this donor special?
2. What impact did their donation have?
3. How to personalize the message?
4. What's an appropriate call-to-action?

Then write the email.
</instructions>

<thinking>
[Claude's reasoning process]
</thinking>

<email>
[Final personalized email]
</email>
```

# üß† Extended Thinking Mode

Extended thinking is Claude's <mark>**internal reasoning capability**</mark> for complex problems, similar to OpenAI's reasoning models.

## Key Differences from Standard CoT

| Aspect | Standard CoT | Extended Thinking |
|--------|--------------|-------------------|
| **Visibility** | Shown in output | Internal (summary optional) |
| **Prompting** | Must request explicitly | Enabled via API parameter |
| **Instruction style** | Step-by-step guidance | High-level goals preferred |
| **Budget** | N/A | Token budget configurable |

## Technical Considerations

- **Minimum budget:** 1024 tokens
- **For >32K thinking:** Use batch processing
- **Language:** Best in English (outputs can be any language)
- **Below minimum:** Use standard CoT with `<thinking>` tags instead

## Prompting for Extended Thinking

### ‚úÖ DO: High-Level Instructions

```markdown
Please think about this math problem thoroughly and in great detail.
Consider multiple approaches and show your complete reasoning.
Try different methods if your first approach doesn't work.
```

### ‚ùå DON'T: Over-Prescribe Steps

```markdown
Think through this math problem step by step:
1. First, identify the variables
2. Then, set up the equation
3. Next, solve for x
...
```

> **Why?** Claude's creativity in approaching problems may exceed your ability to prescribe the optimal thinking process.

## When to Increase Thinking Budget

Extended thinking excels at:

- **Complex STEM problems** - Mathematical proofs, physics
- **Constraint optimization** - Scheduling, resource allocation
- **Thinking frameworks** - Multi-perspective analysis
- **Code with edge cases** - Algorithms requiring verification

## Multishot with Extended Thinking

You can provide examples showing how to think:

```markdown
I'll show you how to solve a math problem, then solve a similar one.

Problem 1: What is 15% of 80?

<thinking>
To find 15% of 80:
1. Convert 15% to a decimal: 15% = 0.15
2. Multiply: 0.15 √ó 80 = 12
</thinking>

The answer is 12.

Now solve this one:
Problem 2: What is 35% of 240?
```

## Self-Verification

Ask Claude to check its work:

```markdown
Write a function to calculate the factorial of a number.
Before you finish, please verify your solution with test cases for:
- n=0
- n=1
- n=5
- n=10
And fix any issues you find.
```

## What NOT to Do

‚ùå **Don't pass thinking back:** Don't include Claude's extended thinking in subsequent prompts‚Äîthis doesn't improve performance.

‚ùå **Don't prefill:** Prefilling assistant responses with extended thinking is explicitly not allowed.

‚ùå **Don't manually edit:** Changing model output after thinking can degrade results.

# üìö Multishot Prompting

Providing examples (multishot/few-shot) is one of the most effective ways to guide Claude's output.

## When Examples Help Most

- Establishing specific output formats
- Teaching domain-specific patterns
- Demonstrating edge case handling
- Calibrating response length and style

## Example Structure

```xml
<examples>
  <example id="1">
    <input>
      Customer complaint: "My order arrived damaged"
    </input>
    <output>
      Category: Shipping
      Sentiment: Negative
      Priority: High
      Suggested action: Offer replacement + discount
    </output>
  </example>
  
  <example id="2">
    <input>
      Customer feedback: "Love the new features!"
    </input>
    <output>
      Category: Product
      Sentiment: Positive
      Priority: Low
      Suggested action: Thank and request review
    </output>
  </example>
</examples>

<task>
Analyze this customer message:
<input>
{{customer_message}}
</input>
</task>
```

## Best Practices

1. **Use 2-5 diverse examples** covering different scenarios
2. **Maintain consistent formatting** across all examples
3. **Include edge cases** if relevant
4. **Use IDs** to clearly link inputs with outputs

# üë§ System Prompts and Roles

System prompts establish Claude's persona and high-level behavior.

## Effective Role Definition

```xml
<system>
You are a senior security consultant specializing in web application security.
You have 15 years of experience in penetration testing and code review.
Your communication style is direct and actionable.
You always cite specific line numbers when identifying issues.
</system>
```

## Role Components

| Component | Purpose | Example |
|-----------|---------|---------|
| **Expertise** | Domain knowledge | "specializing in financial compliance" |
| **Experience** | Calibrate depth | "15 years of experience" |
| **Style** | Communication tone | "concise and technical" |
| **Behaviors** | Specific actions | "always provide examples" |

# üìù Long Context Tips

Claude excels at processing long documents (up to 200K tokens), but benefits from guidance.

## Placement Strategies

1. **Critical instructions FIRST**: Place essential guidance at prompt start
2. **Large documents MIDDLE**: Reference material in the body
3. **Specific queries LAST**: Ask questions after providing context

## Document Delineation

```xml
<documents>
  <document id="1" title="Q1 Financial Report">
    {{document_1_content}}
  </document>
  
  <document id="2" title="Q2 Financial Report">
    {{document_2_content}}
  </document>
</documents>

<task>
Compare the revenue trends between Q1 and Q2, citing specific figures from each document.
</task>
```

## Needle-in-Haystack Queries

For finding specific information in large contexts:

```markdown
The following documents contain our company's HR policies.

<documents>
{{large_policy_documents}}
</documents>

Find and quote the exact policy text regarding:
1. Remote work eligibility requirements
2. Equipment reimbursement limits

Cite the document name and section for each answer.
```

# ‚úÇÔ∏è Prefilling Claude's Response

You can <mark>**start Claude's response**</mark> to control format and reduce unwanted preamble.

## Basic Prefilling

```python
response = client.messages.create(
    model="claude-sonnet-4-20260514",
    messages=[
        {"role": "user", "content": "List the top 3 programming languages for data science."},
        {"role": "assistant", "content": "1."}  # Prefill starts the list
    ]
)
```

## JSON Output Prefilling

```python
response = client.messages.create(
    model="claude-sonnet-4-20260514",
    messages=[
        {"role": "user", "content": "Extract the person's name and age from: 'John is 32 years old.'"},
        {"role": "assistant", "content": "{"}  # Forces JSON output
    ]
)
```

## XML Output Prefilling

```python
response = client.messages.create(
    model="claude-sonnet-4-20260514",
    messages=[
        {"role": "user", "content": "Analyze the sentiment of this review: 'Great product!'"},
        {"role": "assistant", "content": "<analysis>"}  # Forces structured output
    ]
)
```

> **Note:** Prefilling is NOT allowed when extended thinking is enabled.

# üîó Chain Complex Prompts

For multi-step workflows, break prompts into a chain where each step feeds the next.

## Chaining Pattern

```
Prompt 1: Extract key information
    ‚Üì
Output 1 ‚Üí Input 2
    ‚Üì
Prompt 2: Analyze extracted information
    ‚Üì
Output 2 ‚Üí Input 3
    ‚Üì
Prompt 3: Generate final recommendation
```

## Example: Document Analysis Chain

**Step 1: Extraction**
```xml
<task>Extract all financial figures from this document.</task>
<document>{{report}}</document>
<output_format>JSON with figure name, value, and context.</output_format>
```

**Step 2: Analysis**
```xml
<task>Identify trends and anomalies in these figures.</task>
<data>{{step_1_output}}</data>
<output_format>List of observations with significance ratings.</output_format>
```

**Step 3: Recommendation**
```xml
<task>Based on this analysis, provide investment recommendations.</task>
<analysis>{{step_2_output}}</analysis>
<output_format>Executive summary with action items.</output_format>
```

# üîß Practical Examples

## Example 1: Customer Feedback Anonymization

```xml
<role>
You are a data privacy specialist responsible for anonymizing customer feedback
before it's shared with product teams.
</role>

<task>
Anonymize the following customer feedback by:
1. Replacing names with [CUSTOMER]
2. Removing specific dates (replace with [DATE])
3. Generalizing location information
4. Preserving the sentiment and actionable insights
</task>

<feedback>
Hi, I'm John Smith from Seattle. On January 15th, I ordered a laptop 
but received it damaged. I called Sarah in customer service and she 
was very helpful. Please ship a replacement to my address at 123 Main St.
</feedback>

<output_format>
Return only the anonymized text with no additional commentary.
</output_format>
```

## Example 2: Marketing Email with CoT

```xml
<task>
Create a marketing email for our new productivity app targeting remote workers.
</task>

<product_info>
- App name: FocusFlow
- Key feature: AI-powered distraction blocking
- Price: $9.99/month
- Launch date: February 2026
</product_info>

<thinking>
Consider:
1. Pain points of remote workers (distractions, work-life balance)
2. How FocusFlow addresses these
3. Compelling subject line options
4. Call-to-action that drives sign-ups
</thinking>

<email>
Subject: [subject line]

[email body]
</email>
```

## Example 3: Incident Response Analysis

```xml
<role>
You are a senior DevOps engineer investigating a production incident.
</role>

<context>
Our e-commerce platform experienced a 45-minute outage affecting checkout.
You need to analyze the logs and provide a root cause analysis.
</context>

<logs>
{{incident_logs}}
</logs>

<task>
Analyze the logs and provide:
1. Timeline of events leading to the outage
2. Root cause identification
3. Contributing factors
4. Immediate remediation steps taken
5. Long-term prevention recommendations
</task>

<output_format>
Use headers for each section. Include specific log timestamps as evidence.
</output_format>
```

# ‚ö†Ô∏è Common Pitfalls

## Pitfall 1: Vague Instructions

‚ùå **Wrong:**
```markdown
Help me with this code.
```

‚úÖ **Correct:**
```markdown
Review this Python function for:
1. Potential bugs
2. Performance issues
3. Violations of PEP 8

Suggest specific fixes for each issue found.
```

## Pitfall 2: Missing Context

‚ùå **Wrong:**
```markdown
Write a response to this email.
```

‚úÖ **Correct:**
```markdown
<context>
You are the customer success manager at a SaaS company.
The customer has been with us for 2 years and is considering churning.
</context>

<task>
Write a personalized response addressing their concerns and offering solutions.
</task>

<email>
{{customer_email}}
</email>
```

## Pitfall 3: Inconsistent Example Formatting

‚ùå **Wrong:**
```markdown
Example 1: Input "hello" gives greeting
Example 2:
  input: goodbye
  result: farewell
```

‚úÖ **Correct:**
```xml
<example id="1">
  <input>hello</input>
  <output>greeting</output>
</example>
<example id="2">
  <input>goodbye</input>
  <output>farewell</output>
</example>
```

## Pitfall 4: Over-Prescribing Extended Thinking

‚ùå **Wrong (with extended thinking enabled):**
```markdown
Think step by step:
1. First consider X
2. Then analyze Y
3. Finally conclude Z
```

‚úÖ **Correct:**
```markdown
Think deeply about this problem. Consider multiple approaches
and verify your solution before answering.
```

## Pitfall 5: Passing Thinking Back

‚ùå **Wrong:**
```python
# Don't do this
second_response = client.messages.create(
    messages=[
        {"role": "user", "content": f"Based on your thinking: {first_response.thinking}..."}
    ]
)
```

‚úÖ **Correct:**
```python
# Use only the final output
second_response = client.messages.create(
    messages=[
        {"role": "user", "content": f"Based on your analysis: {first_response.content}..."}
    ]
)
```

# üìö References

### Official Documentation

- üìò **[Anthropic Prompt Engineering Overview](https://platform.claude.com/docs/en/docs/build-with-claude/prompt-engineering/overview)** `[üìò Official]`
  Master guide for Claude prompting with technique prioritization.

- üìò **[Be Clear and Direct](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct)** `[üìò Official]`
  Foundation of effective Claude prompting.

- üìò **[Chain of Thought Prompting](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-of-thought)** `[üìò Official]`
  Detailed CoT techniques and examples.

- üìò **[Extended Thinking Tips](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips)** `[üìò Official]`
  Advanced techniques for extended thinking mode.

- üìò **[Use XML Tags](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/use-xml-tags)** `[üìò Official]`
  Structuring prompts with XML.

- üìò **[Multishot Prompting](https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/multishot-prompting)** `[üìò Official]`
  Few-shot example techniques.

### Interactive Resources

- üìò **[GitHub Prompting Tutorial](https://github.com/anthropics/prompt-eng-interactive-tutorial)** `[üìò Official]`
  Interactive examples covering all techniques.

- üìò **[Google Sheets Prompting Tutorial](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8)** `[üìò Official]`
  Lightweight interactive version.

- üìò **[Claude Prompt Library](https://platform.claude.com/docs/en/resources/prompt-library/library)** `[üìò Official]`
  Curated prompts for various use cases.

---

**Parent Article:** [08.00 How to Optimize Prompts for Specific Models](./08.00-how_to_optimize_prompts_for_specific_models.md)

---

<!-- VALIDATION METADATA - DO NOT MODIFY ABOVE THIS LINE -->
<!--
```yaml
article_metadata:
  filename: "08.02-appendix_anthropic_prompting_guide.md"
  type: "appendix"
  parent: "08.00-how_to_optimize_prompts_for_specific_models.md"
  word_count: ~2600
  reading_time_minutes: 10

guide_version:
  provider: "Anthropic"
  url: "https://platform.claude.com/docs/en/docs/build-with-claude/prompt-engineering/overview"
  last_verified: "2026-01-20"
  additional_sources:
    - url: "https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips"
      last_verified: "2026-01-20"
    - url: "https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/chain-of-thought"
      last_verified: "2026-01-20"

cross_references:
  series:
    name: "Prompt Engineering for GitHub Copilot"
    part: "8.2"
    parent: "./08.00-how_to_optimize_prompts_for_specific_models.md"

validations:
  grammar:
    status: "not-started"
    last_run: null
  fact_check:
    status: "not-started"
    last_run: null
    sources_verified: null
```
-->
