---
title: "How to Structure Content for GitHub Copilot Prompt Files"
author: "Dario Airoldi"
date: "2025-12-26"
categories: [tech, github-copilot, prompt-engineering]
description: "Best practices for structuring prompt files with YAML frontmatter, clear content, and advanced patterns for effective GitHub Copilot responses"
---

# How to Structure Content for GitHub Copilot Prompt Files

Designing effective prompt files is key to obtaining accurate and useful responses from GitHub Copilot. Prompt files (`*.prompt.md`) let you define <mark>reusable prompts that generate code or documentation in a structured way</mark>. Here we discuss best practices for structuring your prompt files and note the differences in functionality between **Visual Studio Code** and **Visual Studio**.

## Table of Contents

- [üìã YAML Frontmatter](#-yaml-frontmatter)
- [‚úçÔ∏è Compose Clear and Structured Content](#Ô∏è-compose-clear-and-structured-content)
- [üé® Advanced Prompt Structuring Patterns](#-advanced-prompt-structuring-patterns)
- [üìÅ Organize Supporting Materials](#-organize-supporting-materials)
- [‚öôÔ∏è Environment-Specific Considerations](#Ô∏è-environment-specific-considerations)
- [üß™ Testing and Validating Prompts](#-testing-and-validating-prompts)
- [üéØ Conclusion](#-conclusion)
- [üìö References](#-references)
- [Appendix A: YAML Frontmatter Metadata Reference](#-appendix-yaml-frontmatter-metadata-reference)
- [Appendix B: Tools and Capabilities Reference](#-appendix-tools-and-capabilities-reference)

# üìã YAML Frontmatter

Prompt files may start with a <mark>**YAML frontmatter**</mark> enclosed by `---`. This header configures how the prompt appears in the Chat UI and how it executes:

- <mark>**name**</mark>: Identifier for the slash/hashtag command. If omitted, Copilot uses the filename. 
- <mark>**description**</mark>: Shown when selecting the prompt in the picker. Provides context to your team.
- <mark>**agent**</mark>: Sets the chat mode (`ask`, `edit`, `agent` or a custom agent name). When referencing a custom agent, the prompt inherits that agent's default tools and behavior. See [How to Structure Content for Copilot Agent Files](./04.00-how_to_structure_content_for_copilot_agent_files.md) for details on custom agents.
- <mark>**model**</mark>: Chooses a specific LLM; otherwise Copilot uses the default. 
- <mark>**tools**</mark>: Restricts which tools (e.g., `fetch`, `codebase`, specific MCP servers) the prompt can access. <mark>**Tool Priority**</mark>: Tools specified in the prompt override tools from the referenced agent, which override default tools (Prompt > Agent > Default). 
- **<mark>argument-hint</mark>**: Suggests how to provide arguments when running the prompt (visible in the input field).

These metadata fields are supported in **VS Code** and in **Visual Studio 17.10+**; however, not all features (such as custom agent names or specific tools) may be fully supported by Visual Studio yet. Check the release notes for your version to see which fields are functional.

Here‚Äôs a sample YAML header:

```yaml
---
name: react-form
agent: ask
model: GPT-4
description: "Generate a React form component from a list of fields."
tools: ['codebase', 'fetch']
argument-hint: 'fields=field1:string,field2:number...'
---
```

# ‚úçÔ∏è Compose Clear and Structured Content

The body of a prompt file contains the actual instructions. <mark>Use concise, direct language to convey the task</mark>. Organize content with headings and bullet points to make it easy for both humans and the LLM to follow.

### Define the Role and Objective
<mark>Start by stating the persona and mission</mark>. For example: "You are a senior software engineer preparing a code scaffold for a new feature. Generate a file structure, include doc comments, mark TODOs where logic should be implemented, and create supporting files (e.g., package.json)."

### Use Bullet Points
<mark>Enumerate requirements or tasks clearly. **LLMs process bullet lists effectively**</mark>, which results in more organized responses.  

For example:
- Include comments explaining each function.
- <mark>Add a `TODO` placeholder</mark> in functions that need implementation.
- <mark>Create `.env` placeholders</mark> for environment variables.
- Generate dependency files if needed.

**Example: Scaffolding with TODO and .env Placeholders**

When generating scaffolds, combine `.env` configuration templates with `TODO` markers to guide implementation:

**File: `.env.template`**
```bash
# Copy this file to .env and replace placeholder values

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/myapp
```

**File: `app.py`**
```python
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class AIService:
    """Service for interacting with Azure OpenAI."""
    
    def __init__(self):
        # TODO: Initialize Azure OpenAI client with credentials from environment
        # TODO: Add connection validation and error handling
        pass
    
    def generate_response(self, prompt: str) -> str:
        """
        Generate AI response for the given prompt.
        
        Args:
            prompt: User's input text
            
        Returns:
            Generated response text
        """
        # TODO: Call Azure OpenAI API with prompt
        # TODO: Implement retry logic for transient failures
        # TODO: Add response validation and sanitization
        pass

class DatabaseService:
    """Service for database operations."""
    
    def __init__(self):
        db_url = os.getenv("DATABASE_URL")
        # TODO: Establish database connection using db_url
        # TODO: Implement connection pooling
        pass
    
    def save_interaction(self, prompt: str, response: str) -> None:
        """Save user interaction to database."""
        # TODO: Insert prompt and response into interactions table
        # TODO: Add transaction handling and rollback on error
        pass
```

This approach creates a clear implementation roadmap where developers use GitHub Copilot to fill in the `TODO` sections while the `.env.template` file documents all required configuration.

**About `.env.template` Files:**

`.env.template` files are **generated outputs** from scaffolding prompts, not prompt assets. They should be placed in the root directory of the **generated project**, not in the `.github/prompts/` folder.

**Typical workflow:**
1. **Scaffolding prompt** (e.g., `/scaffold-app`) generates project structure
2. **Output includes** `.env.template` at project root with placeholder values
3. **Developer copies** `.env.template` to `.env` and fills in real values
4. **`.gitignore`** includes `.env` (secrets), but `.env.template` is committed (documentation)

**File placement in generated project:**
```
my-app/                      ‚Üê Generated project root
‚îú‚îÄ‚îÄ .env.template           ‚Üê Committed to repo (no secrets)
‚îú‚îÄ‚îÄ .env                    ‚Üê Local only (.gitignored, contains secrets)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

**Not in prompt folder:**
```
.github/prompts/
‚îú‚îÄ‚îÄ scaffold-app.prompt.md   ‚Üê Prompt that GENERATES .env.template
‚îî‚îÄ‚îÄ (no .env.template here)  ‚Üê Templates are outputs, not inputs
```

For **reusable templates** referenced by multiple prompts, use `.github/prompt-snippets/` for Markdown fragments or `.github/templates/` for file templates, but these are rare‚Äîmost prompts generate templates dynamically based on user requirements.

### Provide an Input Template
For prompts that require user input, include a <mark>**user-editable template**</mark> with placeholders. <mark>Wrap variable sections in double braces</mark> to signal that they should be replaced by the user.

**Important Syntax Distinction:**
- `{{user input placeholder}}` = User fills in before/during execution (input data)
- `#file:path/to/file` = Include file content in chat (VS Code only)
- Markdown link `[text](path)` = Reference for context (may or may not be read)
- Direct embedding = Paste content directly into prompt body

<mark>Microsoft's AI Prompt Book</mark> demonstrates an effective pattern where each placeholder includes both **a field description AND a concrete example**:

```markdown
## Use Case Description
{{Briefly describe the idea, challenge, or opportunity.
e.g., "We want to use generative AI to streamline our employee onboarding process by automating answers to policy questions."}}

## Target Users
{{Who will use the prototype?
e.g., "New employees at a large enterprise, HR support staff."}}

## Expected Inputs
{{What will the system take as input?
e.g., "Natural language questions from employees about policies or processes."}}

## Expected Outputs
{{What should the system return?
e.g., "Helpful answers, links to internal documents, or a checklist of onboarding tasks."}}

## Constraints or Assumptions
{{Are there any limitations or technical context to be aware of?
e.g., "Must work with existing SharePoint knowledge base; IT has approved Azure OpenAI."}}

## Goal
Generate a well-structured set of requirements to guide the rapid prototyping of this solution.
```

This dual-layer approach (instruction + example) helps users understand both **what** to provide and **how** to format it, reducing ambiguity and improving prompt effectiveness.

### Include Examples (Optional)
Providing example input and output demonstrates the expected result. For instance, when instructing Copilot to create a README, show a sample section to illustrate tone and structure.

### Reference Tools, Files and Variables

Prompts can reference <mark>**tools**, **chat variables**, and **files**</mark> to gather context dynamically and perform operations. Understanding these capabilities is essential for creating powerful, context-aware prompts.

#### Chat Variables (VS Code)

Chat variables inject dynamic context into prompts using `${variable}` syntax:

- **`${workspaceFolder}`** - Absolute path to workspace root
- **`${file}`** - Currently active file path
- **`${selection}`** - Currently selected text in editor
- **`${activeEditor}`** - Active editor context and metadata
- **`${lineNumber}`** - Current cursor line number

**Example usage in prompts:**
```markdown
Analyze the code in ${file} and suggest improvements for the selected section:

${selection}
```

**Platform Support:**
- ‚úÖ **VS Code**: Full support for all chat variables
- ‚ö†Ô∏è **Visual Studio**: Limited support; check version documentation

#### File References

Reference specific files in prompts using `#file` syntax:

- **`#file:path/to/file.ts`** - Include file content as context
- **`#file:*.config.json`** - Pattern matching for multiple files
- **Multiple files**: `#file:src/app.ts #file:src/config.ts`

**Example:**
```markdown
Compare the implementations in #file:src/v1/handler.ts and #file:src/v2/handler.ts
```

#### Tools (Built-in Capabilities)

Tools enable prompts to perform operations and gather information. Reference tools using `#tool` syntax:

**Core Built-in Tools:**
- **`#codebase`** - Semantic search across workspace for code patterns
- **`#fetch <url>`** - Retrieve content from web URLs
- **`#web`** - Search the internet for current information

**Example:**
```markdown
Search the codebase for authentication patterns: #codebase "authentication middleware"

Retrieve the latest React documentation: #fetch https://react.dev/reference
```

**Tool Control via YAML:**
Control which tools a prompt can access using the `tools` field:

```yaml
---
name: code-review
tools: ['codebase', 'editor', 'filesystem']  # Local only, no external network
---
```

**Common Tool Combinations:**
- **Local workspace only**: `['codebase', 'editor', 'filesystem']`
- **Research-enabled**: `['codebase', 'editor', 'fetch', 'web_search']`
- **Full access**: `[]` or omit field (all tools enabled)

#### MCP (Model Context Protocol) Servers

MCP servers extend Copilot with custom capabilities. Reference using `@server-name`:

- **`@github`** - GitHub API integration (repos, issues, PRs)
- **`@azure`** - Azure resource management and queries
- **`@custom-server`** - Organization-specific tools

**Example:**
```yaml
---
tools: ['codebase', '@github', '@azure']
---
```

**GitHub MCP Server (Preview - v1.107+):**  
VS Code 1.107+ includes built-in GitHub MCP server:
- Enable: `github.copilot.chat.githubMcpServer.enabled: true`
- Reuses existing GitHub authentication
- Supports both github.com and GHE

#### Platform-Specific Differences

| Feature | VS Code 1.106+ | Visual Studio 17.10+ |
|---------|----------------|----------------------|
| **Chat Variables** | ‚úÖ Full (`${workspaceFolder}`, `${file}`, etc.) | ‚ö†Ô∏è Limited support |
| **File References** | ‚úÖ `#file:path` syntax | ‚ö†Ô∏è Check version docs |
| **Tools** | ‚úÖ Full (`#codebase`, `#fetch`, `#web`) | ‚ö†Ô∏è Partial support |
| **MCP Servers** | ‚úÖ Preview (1.106+) | ‚ùå Not supported |
| **Tool Control** | ‚úÖ `tools` YAML field | ‚ö†Ô∏è Limited |

**Visual Studio Notes:**  
Visual Studio supports fewer chat variables and tools. Check the [official Visual Studio documentation](https://learn.microsoft.com/en-us/visualstudio/ide/copilot-chat-context) for the current list of supported capabilities.

#### Complete Example: Multi-Source Context Gathering

```yaml
---
name: analyze-security
tools: ['codebase', 'filesystem', 'fetch', 'web_search']
description: "Security analysis with external vulnerability lookup"
---

# Security Analysis Prompt

## Gather Context

1. **Active file**: Analyze ${file} for security patterns
2. **Selected code**: Review specific section:
   ${selection}
3. **Related files**: Find authentication code:
   #codebase "authentication security"
4. **Configuration**: Check for sensitive data:
   #file:.env.template #file:config/*.json
5. **External research**: Look up recent vulnerabilities:
   #fetch https://cve.mitre.org/data/downloads/
   #web "latest nodejs security vulnerabilities"

## Analysis Tasks
...
```

**For comprehensive tool documentation**, see [Appendix B: Tools and Capabilities Reference](#appendix-b-tools-and-capabilities-reference) which provides detailed specifications, use cases, security considerations, and platform availability for all tools.

# üé® Advanced Prompt Structuring Patterns

Building on Microsoft's AI Prompt Book approach, sophisticated prompt files often follow a **three-part architecture** that separates concerns and maximizes reusability:

## The Three-Part Prompt Architecture

### 1. System Message
The <mark>**System Message**</mark> defines the AI's role, expertise level, mission, and operational guidelines. It sets the context for **how** the AI should behave throughout the interaction.

**Key elements to include:**
- **Persona definition**: "You are a senior solution architect..."
- **Core mission**: "...tasked with gathering and structuring solution requirements..."
- **Step-by-step process**: Numbered instructions for systematic execution
- **Deliverable specification**: Clear description of expected output format
- **Quality criteria**: Standards the output must meet

**Example System Message:**
```markdown
## System Message

You are a senior software engineer preparing code scaffolding to support a rapid prototype for a developer using GitHub Copilot.

Your mission:
- Generate a code scaffold (file structure, function/method definitions, class stubs)
- Include clear, concise doc-comments describing intended behavior, input/output, and edge cases
- Add TODO markers signaling where GitHub Copilot should implement logic
- Include .env placeholders and dependency files (requirements.txt, package.json, csproj)
- Reflect the use case, technologies, data access patterns, and requirements as specified
- Format each file using appropriate code fences and filenames
- Output **only** scaffold code - no implementation - so developers can use GitHub Copilot to build the full solution

This ensures Copilot has the right structural context to generate meaningful code while keeping architecture aligned with the developer's intent.
```

### 2. User Prompt Template
The <mark>**User Prompt Template**</mark> provides a structured input form with semantic sections and placeholder syntax. Each field should include:
- **Section heading** describing the information category
- **Placeholder with instruction** in `{{double braces}}`
- **Inline example** showing concrete input (using `e.g., "..."` format)

**Example User Prompt Template:**
```markdown
## User Prompt Template

## Use Case
{{Describe the prototype use case and goal.
e.g., "Search and summarize HR policy documents via natural language queries."}}

## Target Functionality
{{High-level behavior to enable via GitHub Copilot.
e.g., "Accept user question, retrieve relevant policy docs, generate short summaries, support follow-ups."}}

## Technologies / Frameworks
{{List languages, frameworks, and services.
e.g., "Python, Semantic Kernel, Azure OpenAI, Azure AI Search"}}

## Data Access
{{Describe data source or access methods.
e.g., "Local JSON/CSV file of policy documents, no external APIs"}}

## Goal
Generate scaffold code optimized for use with GitHub Copilot.
```

### 3. Example Usage
The <mark>**Example Usage**</mark> section demonstrates proper prompt execution by showing the User Prompt Template **filled out** with realistic, concrete values. This serves multiple purposes:
- **Training users** on appropriate level of detail
- **Validating template design** by testing with real scenarios
- **Providing copy-paste starting points** for common use cases

**Example Usage Section:**
```markdown
## Example Usage

## Use Case
Prototype for searching and summarizing HR policy documents via natural language queries.

## Target Functionality
- Accept a user question
- Search across a set of HR policy documents
- Retrieve relevant documents and generate brief summaries
- Support follow-up queries (e.g., "What is the maternity leave policy?")

## Technologies / Frameworks
Python, Semantic Kernel, Azure OpenAI, Azure AI Search

## Data Access
- Local JSON/CSV file containing policy documents
- No external APIs required for data access

## Goal
Generate scaffold code for use with GitHub Copilot.
```

## Dynamic Input Collection

Modern prompt files can collect input from multiple sources in a flexible, intelligent way rather than requiring manual template filling. This approach enables more natural workflows and reduces friction for users.

**Available Input Sources:**

1. **Explicit User Input** (Manual templates with `{{placeholders}}`)
   - User fills in structured template before submission
   - Highest priority when conflicts occur
   - Best for: Complex requirements gathering, initial project setup

2. **Active File/Selection**
   - Automatically use content from currently open file or selected text
   - No manual input needed if user has file open
   - Best for: Refactoring, reviewing, transforming existing content

3. **Attached Files** (Using `#file`)
   - User attaches files directly in chat: `#file:path/to/document.md`
   - Supports multiple files simultaneously
   - Best for: Processing specific documents, comparing files

4. **Workspace Context**
   - Automatically discover files by common patterns or content analysis
   - Search for configuration files, detect project structure
   - Best for: Project-aware operations, smart defaults

5. **Chat Variables** (VS Code)
   - `${workspaceFolder}`, `${file}`, `${selection}`, `${activeEditor}`
   - Dynamically inject current context into prompts
   - Best for: Context-aware code generation

6. **Tool Integration**
   - `#codebase` - Semantic search across repository
   - `#fetch <url>` - Pull external documentation
   - Web search for latest information
   - Best for: Research, documentation lookup, external resources

**Example: Multi-Source Input Strategy**

Here's how a prompt can intelligently combine multiple sources:

```markdown
## Input Sources (Collect from all available sources)

**Gather information from ALL available sources:**
- User-provided information in chat (structured sections or `{{placeholders}}`)
- Active file or selection (detect content type automatically)
- Attached files with `#file` (analyze content, don't rely solely on filenames)
- Workspace context files (search by common names or content patterns)
- Explicit file paths provided as arguments

**Content Detection (intelligent analysis):**
- Analyze file structure and content to determine type
- Look for metadata patterns (dates, speakers, timestamps)
- Identify language, framework, or technology from imports/syntax
- Detect purpose from content structure (config, source, docs)

**Information Priority (when conflicts occur):**
1. **Explicit user input** - Override everything
2. **Active file/selection** - Current workspace context
3. **Attached files** - Explicitly provided resources
4. **Workspace context** - Discovered automatically
5. **Inferred/derived** - Calculated from other sources

**Workflow Example:**
1. Check for explicit user input (highest priority)
2. Check active file - analyze to identify type/purpose
3. Check attached files - analyze content
4. Search workspace for related files by pattern
5. Merge information using priority rules
6. Ask user for clarification only if critical info missing
```

**Practical Workflow Example: Session Summary Generation**

A real-world prompt (like `article-generate-techsession-summary.prompt.md`) demonstrates this multi-source approach:

```markdown
**Scenario A: User has files open**
1. User opens `SUMMARY.md` in editor
2. Runs `/techsession-summary`
3. Prompt detects open file contains session metadata
4. Auto-searches workspace for `transcript.txt`
5. Generates summary, outputs to `SUMMARY.md` (overwrites existing)

**Scenario B: User provides partial info**
1. User types: `/techsession-summary {{session title: "AI Agents Workshop"}}`
2. Prompt uses title from user input (priority 1)
3. Searches workspace for summary/transcript files
4. Finds files, extracts remaining metadata
5. Generates summary with user-specified title

**Scenario C: User attaches files**
1. User types: `/techsession-summary #file:session-notes.md #file:recording.txt`
2. Prompt analyzes attached files (detect types by content)
3. Merges metadata from both files
4. Generates new summary with descriptive filename

**Scenario D: Nothing available**
1. User runs `/techsession-summary` in empty folder
2. Prompt lists current directory contents
3. Asks user to either:
   - Attach files with `#file:`
   - Provide file paths as arguments
   - Navigate to correct folder
```

**Benefits of Multi-Source Strategy:**

- **Flexibility**: Works with various user workflows
- **Efficiency**: Reduces manual input when context available
- **Intelligence**: Makes smart decisions based on available data
- **Graceful degradation**: Falls back to asking user when needed
- **Priority-based conflicts**: Clear rules for handling duplicates

**When to Use Each Approach:**

| Approach | When to Use | User Effort | Flexibility |
|----------|-------------|-------------|-------------|
| **Manual Template** | Complex requirements, initial setup | High | Low |
| **Active File** | Refactoring, reviewing existing code | None | High |
| **Attached Files** | Specific documents, multiple inputs | Medium | High |
| **Workspace Context** | Project-aware operations | None | High |
| **Chat Variables** | Context-aware generation | None | Medium |
| **Tool Integration** | Research, external docs | Low | High |
| **Combined Strategy** | Production prompts | Low-Medium | Very High |

Modern prompts should default to **combined strategy** for best user experience, using manual templates only as a fallback or for complex scenarios where auto-detection isn't sufficient.

## Organizing Prompts by Categories

Microsoft's AI Prompt Book organizes prompts into **engagement-stage categories** that align with solution development lifecycle:

- **üîç Discovery**: Use case ideation, evaluation, research, resource gathering
- **‚ö° Rapid Prototyping**: Requirements definition, data generation, code scaffolding, code generation
- **üöö Delivery**: Architecture design, deployment planning, webinar content
- **üíª GitHub Copilot**: Repository-specific prompts for in-IDE workflows

Consider organizing your `.github/prompts/` directory with subdirectories matching your team's workflow stages:

```
.github/prompts/
‚îú‚îÄ‚îÄ discovery/
‚îÇ   ‚îú‚îÄ‚îÄ use-case-ideation.prompt.md
‚îÇ   ‚îî‚îÄ‚îÄ requirements-gathering.prompt.md
‚îú‚îÄ‚îÄ development/
‚îÇ   ‚îú‚îÄ‚îÄ code-scaffolding.prompt.md
‚îÇ   ‚îî‚îÄ‚îÄ code-generation.prompt.md
‚îú‚îÄ‚îÄ quality/
‚îÇ   ‚îú‚îÄ‚îÄ grammar-review.prompt.md
‚îÇ   ‚îî‚îÄ‚îÄ security-review.prompt.md
‚îî‚îÄ‚îÄ documentation/
    ‚îú‚îÄ‚îÄ article-writing.prompt.md
    ‚îî‚îÄ‚îÄ api-docs-generation.prompt.md
```

## Recommended Model Specification

Include a <mark>**Recommended Model**</mark> field in your prompt documentation (can be in YAML frontmatter or as a Markdown section) to guide users on model selection:

```yaml
---
name: code-scaffolding
model: o3  # or "gpt-5", "claude-sonnet-4.5"
description: "Generate code scaffolds for GitHub Copilot implementation"
---
```

Or as a Markdown section:
```markdown
### Recommended Model
o3 or GitHub Copilot (for in-IDE scaffolding)
gpt-5 (for Azure AI Foundry Chat Playground)
```

# üìÅ Organize Supporting Materials

Complex prompts often require reusable content or deeper context.  
Organize these resources strategically:

- <mark>**Prompt snippets**</mark>: Create a folder such as `.github/prompt-snippets/` for reusable text fragments (e.g., code review guidelines, test boilerplates). **To use them**: reference via `#file:path` in chat, embed directly in prompt body, or copy-paste when needed. <mark>**Note**: GitHub Copilot does NOT support automatic "include" syntax like `{{#include}}`</mark>.
- <mark>**Custom agents**</mark>: For reusable personas that multiple prompts can reference, create `.agent.md` files in `.github/agents/`. See [How to Structure Content for Copilot Agent Files](./04.00-how_to_structure_content_for_copilot_agent_files.md) for detailed guidance on agent design.
- <mark>**Project documentation**</mark>: Use a `.copilot/context/` (optional) folder to store rich information‚ÄîAPI contracts, data schemas, domain terms, architecture decisions and diagrams‚Äîwhich <mark>the Copilot engine can search</mark>. VS Code and Visual Studio both index these files to improve the relevance of suggestions.
- **Example outputs**: Including example outputs (e.g., a table of tests to generate) can guide the model's formatting and structure. When adding examples, clearly mark them so readers know they're illustrative.

## Targeted Instructions with .instructions.md Files

In addition to prompt files (`.prompt.md`), Visual Studio 17.12+ supports <mark>**targeted instruction files**</mark> that automatically apply context based on file patterns. These `.instructions.md` files provide more flexibility than a single global `copilot-instructions.md` file.

**Key Features:**
- Multiple instruction files for different contexts (languages, frameworks, file types)
- Automatic application based on glob patterns
- YAML frontmatter for configuration

**File Structure:**
```markdown
---
description: "C# coding standards for this project"
applyTo: "**/*.cs"
---

# C# Instructions

- Write clear and concise comments for each function.
- Use PascalCase for component names, method names, and public members.
- Use camelCase for private fields and local variables.
- Add a newline before the opening curly brace of any code block.
- Ensure that the final `return` statement of a method is on its own line.
```

**Usage Pattern:**
1. Create `.github/instructions/` directory
2. Add `*.instructions.md` files for different contexts
3. Use `applyTo` glob patterns to target specific files
4. Enable in Visual Studio via Tools > Options > GitHub > Copilot > Copilot Chat

**Example Organization:**
```
.github/instructions/
‚îú‚îÄ‚îÄ csharp-backend.instructions.md     (applyTo: "src/backend/**/*.cs")
‚îú‚îÄ‚îÄ typescript-frontend.instructions.md (applyTo: "src/frontend/**/*.ts")
‚îú‚îÄ‚îÄ python-ml.instructions.md          (applyTo: "ml/**/*.py")
‚îî‚îÄ‚îÄ sql-migrations.instructions.md     (applyTo: "db/migrations/**/*.sql")
```

When Copilot processes your request, it automatically detects and applies relevant instruction files based on your current context. The applied instructions are listed in the References section of Copilot's response.

For more examples, see the [instruction samples on GitHub](https://github.com/github/awesome-copilot).

# üìè Content Length Best Practices

When designing prompt files, length directly impacts performance, reliability, and user experience. Understanding token budgets and optimal file sizes helps create prompts that execute efficiently without overwhelming the AI's context window.

## Token Budget Considerations

**What Are Tokens?**
- Tokens are the basic units that language models process (roughly 1 token ‚âà 4 characters or 0.75 words)
- Every prompt file consumes tokens from the available context window
- Larger prompts increase:
  - **Context window consumption** - Less room for code, file contents, and conversation history
  - **Response latency** - More tokens to process means longer wait times
  - **Risk of truncation** - In multi-turn conversations, earlier context may be dropped

**Context Window Reality:**
- GPT-4: 128K tokens (~96,000 words total context)
- Claude Sonnet: 200K tokens (~150,000 words total context)
- **But:** Context is shared between prompt, conversation history, referenced files, and response generation

## Size Guidelines by Prompt Type

| Prompt Type | Recommended Max | Typical Size | Reason |
|-------------|-----------------|--------------|--------|
| **Simple Task** | 500 tokens (~375 words) | 200-300 tokens | Fast execution, clear focus, minimal overhead |
| **Multi-Step Workflow** | 1,500 tokens (~1,100 words) | 800-1,200 tokens | Room for detailed phase instructions |
| **Orchestrator** | 2,500 tokens (~1,875 words) | 1,500-2,000 tokens | Complex coordination, handoff logic, multiple agents |
| **Scaffolding** | 2,000 tokens (~1,500 words) | 1,000-1,500 tokens | Template generation with examples and placeholders |
| **Review/Audit** | 2,000 tokens (~1,500 words) | 1,200-1,800 tokens | Checklists, validation criteria, output formats |

**Rule of Thumb:** If your prompt exceeds **2,500 tokens** (~1,875 words), consider refactoring.

## Measuring Prompt Length

### Quick Estimation
```bash
# Word count (multiply by 1.33 for token estimate)
wc -w .github/prompts/my-prompt.prompt.md

# Character count (divide by 4 for rough token estimate)
wc -m .github/prompts/my-prompt.prompt.md
```

### Accurate Token Count
Use OpenAI's tiktoken library or online tools:
```python
import tiktoken

def count_tokens(file_path, encoding_name="cl100k_base"):
    encoding = tiktoken.get_encoding(encoding_name)
    with open(file_path, 'r') as f:
        text = f.read()
    return len(encoding.encode(text))

tokens = count_tokens('.github/prompts/my-prompt.prompt.md')
print(f"Token count: {tokens}")
```

## When Prompts Are Too Large

### Strategy 1: Split into Multiple Prompts
**Problem:** Single 3,000-token prompt tries to handle research, generation, and validation.

**Solution:** Create specialized prompts with handoffs:
```yaml
# research-api.prompt.md (800 tokens)
---
name: research-api
handoffs:
  - prompt: generate-api
    description: "Generate API implementation"
---

# generate-api.prompt.md (1,200 tokens)
---
name: generate-api
handoffs:
  - prompt: validate-api
    description: "Validate generated API"
---

# validate-api.prompt.md (600 tokens)
---
name: validate-api
---
```

### Strategy 2: Move Reusable Content to Instructions
**Problem:** Prompt includes 400 tokens of language-specific coding standards.

**Solution:** Extract to instruction file:
```yaml
# Before: In prompt (2,400 tokens total)
---
name: create-react-component
---

You are a React developer. Follow these standards:
- Use functional components with hooks
- Add PropTypes validation
- Include JSDoc comments
[... 400 tokens of React guidelines ...]

Generate a component for ${input:componentName}...

# After: Split into prompt + instruction (prompt: 2,000 tokens)
---
name: create-react-component
---

Generate a React component for ${input:componentName}...
```

```yaml
# .github/instructions/react-standards.instructions.md (400 tokens)
---
applyTo: "**/*.tsx,**/*.jsx"
---

# React Component Standards
- Use functional components with hooks
- Add PropTypes validation
- Include JSDoc comments
[... guidelines ...]
```

### Strategy 3: Reference External Documentation
**Problem:** Prompt includes lengthy API specifications or schema definitions.

**Solution:** Use `#fetch` to load content dynamically:
```yaml
# Before: Embedded schema (2,800 tokens)
---
name: generate-api-client
---

Use this API schema:
```json
{
  "openapi": "3.0.0",
  "paths": { ... 1,500 tokens ... }
}
--- ```

Generate a client...

# After: Dynamic reference (1,200 tokens)
---
name: generate-api-client
tools: ['fetch']
---

Fetch the API schema from `.copilot/context/api-schema.json` using #tool:fetch.

Generate a TypeScript client based on the schema...
```

### Strategy 4: Create Custom Agent
**Problem:** Prompt contains 500 tokens of role definition reused across 10+ prompts.

**Solution:** Extract to agent file:
```yaml
# Before: Repeated in every prompt
---
name: review-security
---

You are a senior security engineer with expertise in OWASP Top 10...
[... 500 tokens ...]

Review ${selection} for vulnerabilities...

# After: Reusable agent
# security-reviewer.agent.md
---
description: "Senior security engineer specialized in OWASP Top 10"
tools: ['codebase', 'fetch']
---

You are a senior security engineer with expertise in OWASP Top 10...
[... 500 tokens ...]
```

```yaml
# Prompts now reference agent (50 tokens each)
---
name: review-security
agent: security-reviewer
---

Review ${selection} for vulnerabilities...
```

## Length Optimization Techniques

### 1. Remove Redundant Examples
**Before (1,800 tokens):**
```markdown
## Example 1: Button Component
[... 200 tokens ...]

## Example 2: Input Component  
[... 200 tokens ...]

## Example 3: Card Component
[... 200 tokens ...]
```

**After (1,000 tokens):**
```markdown
## Example: Button Component
[... 200 tokens ...]

For more examples, see `.copilot/context/component-examples.md`
```

### 2. Use Concise Bullet Points
**Before (600 tokens):**
```markdown
When generating components, you should always ensure that you include comprehensive error handling. This means wrapping operations in try-catch blocks, validating all inputs before processing, and providing meaningful error messages to users...
```

**After (250 tokens):**
```markdown
## Error Handling
- Wrap operations in try-catch blocks
- Validate inputs before processing
- Provide meaningful error messages
```

### 3. Link to Context Files Instead of Embedding
**Before (2,200 tokens):**
```markdown
## Database Schema
[... 800 tokens of schema definitions ...]

## API Endpoints
[... 600 tokens of endpoint specs ...]
```

**After (1,200 tokens):**
```markdown
## Database Schema
See `.copilot/context/dataschemas/user-schema.md` for complete schema.

## API Endpoints  
See `.copilot/context/apis/user-endpoints.md` for endpoint specifications.
```

## Impact of Length on Performance

| Prompt Size | Typical Response Time | Context Remaining | Best For |
|-------------|----------------------|-------------------|----------|
| < 500 tokens | 2-5 seconds | 95%+ | Quick tasks, simple queries |
| 500-1,500 tokens | 5-10 seconds | 85-95% | Standard workflows |
| 1,500-2,500 tokens | 10-15 seconds | 75-85% | Complex orchestration |
| 2,500-4,000 tokens | 15-25 seconds | 60-75% | ‚ö†Ô∏è Use sparingly |
| > 4,000 tokens | 25+ seconds | < 60% | üî¥ Refactor required |

**Note:** Times vary based on model, server load, and complexity. These are approximate guidelines.

## Validation Checklist

Before committing a prompt file, verify:

- [ ] **Token count** < 2,500 for standard prompts, < 3,500 for orchestrators
- [ ] **No embedded content** that could be in `.copilot/context/` or instruction files
- [ ] **Examples** limited to 1-2 representative cases
- [ ] **Role definitions** extracted to agent files if reused 3+ times
- [ ] **Schemas/specs** referenced via `#fetch` instead of embedded
- [ ] **Bullet points** used instead of verbose paragraphs
- [ ] **Test** prompt with typical inputs to confirm performance

By maintaining optimal prompt file sizes, you ensure fast, reliable execution while maximizing the context available for code analysis and generation.

# ‚öôÔ∏è Environment-Specific Considerations

| Feature or Recommendation | VS Code (1.106+ Preview) | Visual Studio 17.10+ |
|---|---|---|
| **<mark>.prompt.md support</mark>** | Yes. Slash commands `/promptName` run workspace or user prompts. | Yes, since version 17.10. Reference with `#prompt:promptName` in chat input. |
| **<mark>Prompt invocation syntax</mark>** | `/promptName` - Slash commands invoke prompts directly | `#prompt:` - Reference prompts as context in chat using `#prompt:promptName` |
| **<mark>.instructions.md support</mark>** | Support varies; check VS Code release notes for current status | Yes, since version 17.12. Files in `.github/instructions/` with `applyTo` glob patterns. |
| **<mark>User prompt files</mark>** | Supported. Stored in `~/.config/Code/User/prompts` (Linux) or `%APPDATA%\Code\User\prompts` (Windows). Appear across all workspaces as slash commands. | Not supported. Only workspace prompts are recognized. |
| **<mark>Tools and variables</mark>** | Extensive support for `#fetch`, `#codebase`, `${file}`, `${selection}`, etc. | Limited support; see Visual Studio docs for current tools and variables. |
| **<mark>Custom agents</mark>** | `.agent.md` files in `.github/agents` define specialized personas. Available in VS Code 1.106+ (Preview). | Agent mode available in VS 17.14+. Custom agent profiles can be defined, but mechanism differs from VS Code. |

# üß™ Testing and Validating Prompts

Before sharing prompts with your team, test them systematically to ensure consistent, high-quality results.

## Manual Testing Checklist

### 1. Basic Functionality
- [ ] Prompt appears in the command picker (`/promptName` in VS Code)
- [ ] YAML frontmatter parses without errors
- [ ] Description displays correctly in the picker
- [ ] Invoking the prompt produces a response

### 2. Input Validation
- [ ] Variables (`${selection}`, `${file}`, etc.) resolve correctly
- [ ] User input prompts (`${input:varName}`) display with correct placeholder
- [ ] Missing required inputs produce helpful error messages

### 3. Tool Verification
- [ ] Referenced tools (`#tool:codebase`, etc.) are available
- [ ] Tool outputs are incorporated into the response
- [ ] Tool restrictions in `tools` array are respected

### 4. Output Quality
- [ ] Response format matches expectations
- [ ] Generated code compiles/runs without errors
- [ ] Output follows project coding standards

## Testing Different Scenarios

Test prompts with varied inputs to verify robustness:

| Scenario | What to Test |
|----------|--------------|
| **Empty selection** | Does prompt handle `${selection}` when nothing is selected? |
| **Large file** | Does prompt work with files > 1000 lines? |
| **Different languages** | If language-agnostic, test with multiple file types |
| **Edge cases** | Test with unusual but valid inputs |
| **Error paths** | Test with intentionally invalid inputs |

## Validation Test Prompt

Use this meta-prompt to systematically validate any prompt:

```markdown
I'm testing the /{{prompt-name}} prompt. Please:

1. Show me the exact inputs you received (variables, selection, file context)
2. Describe what you understood the task to be
3. Generate a minimal example output
4. List any assumptions you made

This helps me verify the prompt is working as designed.
```

## Common Issues and Fixes

| Issue | Symptom | Fix |
|-------|---------|-----|
| Prompt not found | Doesn't appear in picker | Check file location (`.github/prompts/`) and extension (`.prompt.md`) |
| Variables empty | `${selection}` shows as literal text | Ensure text is selected before invoking |
| Wrong agent | Prompt uses unexpected behavior | Check `agent` field in frontmatter |
| Tool errors | "Tool not available" messages | Verify tool names in `tools` array |
| Inconsistent output | Results vary widely | Add explicit output format in prompt body |

## Team Review Process

Before merging prompt files to the shared repository:

1. **Peer test** ‚Äî Have another team member run the prompt without guidance
2. **Document** ‚Äî Add usage examples to your team's prompt catalog
3. **Changelog** ‚Äî Note significant changes in commit messages
4. **Monitor** ‚Äî Collect feedback after rollout, iterate as needed

# üéØ Conclusion

<mark>Effective prompt-file design combines a well-crafted YAML header with a clear, structured body and often includes templates or examples</mark>. For sophisticated, reusable prompts, consider adopting the **three-part architecture** (System Message, User Prompt Template, Example Usage) demonstrated by Microsoft's AI Prompt Book‚Äîthis pattern separates concerns, maximizes reusability, and provides clear guidance for both AI models and human users. By respecting the official file locations (e.g., `.github/prompts/` for prompt files), organizing prompts by workflow categories, and understanding the differences between VS Code and Visual Studio capabilities, you can create prompt libraries that provide consistent and high-quality results across your development environments.

---

# ‚ö†Ô∏è Common Mistakes

Even experienced teams make structural mistakes when creating prompt files. These errors reduce effectiveness, create maintenance challenges, or cause prompts to fail silently. Here are the most common pitfalls and how to avoid them.

## Mistake 1: Invalid or Missing YAML Frontmatter

**Problem**: YAML syntax errors or missing delimiters prevent the prompt from being recognized.

**‚ùå Bad examples:**
```yaml
# Missing closing delimiter
---
name: create-component
description: Generate React component

# Prompt body starts here without closing ---
```

```yaml
# Invalid YAML syntax
---
name: create-component
description: Generate component
tools: [fetch search]   # Missing commas
model: Claude Sonnet 4  # Unquoted string with spaces
---
```

**‚úÖ Solution: Proper YAML structure:**
```yaml
---
name: create-component
description: "Generate React component with TypeScript"
tools: [fetch, search]
model: "Claude Sonnet 4"
---

# Prompt body begins after closing delimiter
```

**Validation checklist:**
- [ ] Opening `---` on first line
- [ ] Closing `---` before prompt body
- [ ] Quoted strings containing spaces or special characters
- [ ] Proper array syntax with commas
- [ ] Valid field names (check VS Code docs for supported fields)

## Mistake 2: Vague or Ambiguous Instructions

**Problem**: Prompts that are too general produce inconsistent results across different contexts.

**‚ùå Bad example:**
```markdown
---
name: improve-code
description: Make the code better
---

Improve the selected code.
```

**What's wrong:**
- "Better" is subjective (performance? readability? security?)
- No criteria for evaluation
- No output format specified
- No examples provided

**‚úÖ Solution: Specific, measurable criteria:**
```markdown
---
name: refactor-performance
description: Optimize code for performance with benchmark comparison
---

# Performance Optimization

Analyze the selected code and optimize for:
1. **Time complexity** - Reduce algorithmic complexity where possible
2. **Memory usage** - Eliminate unnecessary allocations
3. **I/O operations** - Batch operations, use caching

## Output Format

**Before:**
```[language]
[Original code]
```

**After:**
```[language]
[Optimized code]
```

**Improvements:**
- [Specific optimization applied]
- [Benchmark: X% faster / Y% less memory]
- [Trade-offs considered]

## Example

**Before:**
```python
for item in items:
    result = expensive_function(item)
    process(result)
```

**After:**
```python
results = [expensive_function(item) for item in items]
for result in results:
    process(result)
```

**Improvement:** Batch processing reduces function call overhead by 40%.
```

## Mistake 3: Context Overload

**Problem**: Prompts that try to handle every edge case become too long and consume excessive context.

**‚ùå Bad example:**
```markdown
---
name: create-api-endpoint
---

Create an API endpoint. Make sure to:

- Use Express.js or Fastify (choose based on project dependencies)
- Implement GET, POST, PUT, DELETE as needed
- Add request validation (use Joi, Zod, or class-validator)
- Include error handling for:
  - Validation errors
  - Database errors
  - Authentication errors
  - Authorization errors
  - Network errors
  - Timeout errors
  [... 300 more lines of edge cases and options ...]
```

**‚úÖ Solution: Focus on the happy path, reference instructions for standards:**
```markdown
---
name: create-api-endpoint
tools: [fetch]
---

# Create API Endpoint

Generate a RESTful API endpoint following our team standards.

## Required Elements

1. **Route definition** with proper HTTP method
2. **Request validation** using team's validator (#file:.github/instructions/api-validation.instructions.md)
3. **Controller function** with error handling
4. **Response format** matching API standard

## Example Request

```http
POST /api/v1/users
Content-Type: application/json

{
  "name": "Jane Doe",
  "email": "jane@example.com"
}
```

## Example Response

```json
{
  "success": true,
  "data": {
    "id": "123",
    "name": "Jane Doe",
    "email": "jane@example.com",
    "createdAt": "2025-12-25T10:00:00Z"
  }
}
```

For full API standards, see `.github/instructions/api-standards.instructions.md`.
```

**Benefits:**
- Concise prompt (200 tokens vs. 2000 tokens)
- Standards centralized in instruction files
- Easier to maintain and update

## Mistake 4: Missing Examples

**Problem**: Abstract instructions without concrete examples lead to unpredictable outputs.

**‚ùå Bad example:**
```markdown
---
name: generate-test
---

Generate unit tests for the selected code. Include edge cases.
```

**‚úÖ Solution: Provide concrete examples:**
```markdown
---
name: generate-test
---

# Generate Unit Tests

Create comprehensive unit tests covering:
- Happy path (normal input)
- Edge cases (empty input, null, undefined)
- Error conditions (invalid input, exceptions)

## Example

**Input Function:**
```typescript
function calculateDiscount(price: number, percentage: number): number {
  if (percentage < 0 || percentage > 100) {
    throw new Error('Invalid percentage');
  }
  return price * (percentage / 100);
}
```

**Generated Tests:**
```typescript
describe('calculateDiscount', () => {
  it('calculates discount for valid inputs', () => {
    expect(calculateDiscount(100, 10)).toBe(10);
    expect(calculateDiscount(50, 20)).toBe(10);
  });

  it('handles edge cases', () => {
    expect(calculateDiscount(100, 0)).toBe(0);
    expect(calculateDiscount(100, 100)).toBe(100);
  });

  it('throws error for invalid percentage', () => {
    expect(() => calculateDiscount(100, -1)).toThrow('Invalid percentage');
    expect(() => calculateDiscount(100, 101)).toThrow('Invalid percentage');
  });
});
```

Follow this pattern for the selected code.
```

## Mistake 5: Incorrect Agent or Tool Configuration

**Problem**: Specifying agents or tools that don't exist or aren't available in the current IDE.

**‚ùå Bad examples:**
```yaml
---
name: refactor-code
agent: refactor-bot      # Agent doesn't exist
tools: [magic-analyzer]  # Invalid tool
---
```

**‚úÖ Solution: Use valid agents and tools:**
```yaml
---
name: refactor-code
agent: agent             # Valid: 'ask', 'edit', 'agent'
tools: [fetch, search]   # Valid built-in tools
---
```

**Valid agent modes (VS Code):**
- `ask` - Conversational responses (default)
- `edit` - Direct code modifications
- `agent` - Autonomous multi-step execution
- `@agentName` - Custom agent reference (e.g., `@planner`)

**Common valid tools:**
- `fetch` - Retrieve remote content
- `search` - Search codebase
- `file` - File operations
- `terminal` - Terminal commands
- Check VS Code docs for complete list

## Mistake 6: Hardcoded File Paths or References

**Problem**: Prompts that reference specific file paths break when project structure changes.

**‚ùå Bad example:**
```markdown
---
name: update-config
---

Update the configuration in `/src/config/app.config.ts` with the new settings.
```

**Problem:** Prompt fails if file moves to `src/settings/` or project uses different structure.

**‚úÖ Solution: Use variables and pattern matching:**
```markdown
---
name: update-config
---

Update the application configuration file.

**Locate the config file by searching for:**
- Filename pattern: `*config*.ts` or `*settings*.ts`
- Typical locations: `src/config/`, `src/settings/`, `config/`
- Content contains: `export default {` or `export const config`

**Changes to apply:**
[Describe configuration changes]

**If multiple config files exist:**
Ask user to select the correct file before proceeding.
```

## Mistake 7: No Variable Substitution

**Problem**: Prompts that require manual editing for each use instead of accepting arguments.

**‚ùå Bad example:**
```markdown
---
name: create-react-component
---

Create a React component called "MyComponent".
```

User must edit prompt body each time to change component name.

**‚úÖ Solution: Use variable substitution (VS Code 1.99+):**
```yaml
---
name: create-react-component
description: "Generate React component with TypeScript"
argument-hint: "Component name (PascalCase)"
variables:
  componentName:
    description: "Name of the component to create"
    required: true
---

# Create React Component: ${componentName}

Generate a functional React component named `${componentName}` with:

1. **File:** `${componentName}.tsx`
2. **Props interface:** `${componentName}Props`
3. **Styles:** `${componentName}.module.css`

## Example Output

```tsx
import React from 'react';
import styles from './${componentName}.module.css';

interface ${componentName}Props {
  // Props here
}

export const ${componentName}: React.FC<${componentName}Props> = (props) => {
  return (
    <div className={styles.container}>
      {/* Implementation */}
    </div>
  );
};
```
```

**Usage:** `/create-react-component Button` ‚Üí substitutes `${componentName}` with `Button`

## Mistake 8: Ignoring IDE Compatibility

**Problem**: Using VS Code-specific features in prompts that must work in Visual Studio or JetBrains.

**‚ùå Bad example (VS Code only):**
```yaml
---
name: analyze-codebase
tools: [fetch, search, terminal]
model: "Claude Sonnet 4"
---

Use #codebase to search the entire repository...
```

**Problems:**
- `tools` field not supported in Visual Studio
- `model` field not supported in Visual Studio
- `#codebase` not available in Visual Studio

**‚úÖ Solution: Cross-IDE compatible prompt:**
```yaml
---
name: analyze-codebase
description: "Analyze repository for architectural patterns"
---

# Codebase Analysis

Search the repository for architectural patterns:

1. Identify main architectural layers
2. List common design patterns used
3. Document key dependencies

**Search approach:**
- Use `@workspace` (available in all IDEs)
- Search for: class definitions, interface declarations, module exports
- Focus on entry points: `main.*`, `index.*`, `app.*`
```

## Key Takeaways

‚úÖ **DO:**
- Validate YAML syntax before committing
- Provide specific, measurable criteria
- Keep prompts focused (use instructions for standards)
- Include concrete examples
- Use valid agent modes and tools
- Parameterize with variables instead of hardcoding
- Test prompts in all target IDEs

‚ùå **DON'T:**
- Skip YAML delimiters or use invalid syntax
- Write vague instructions like "improve code"
- Create 1000-line prompts covering every edge case
- Omit examples
- Reference non-existent agents or tools
- Hardcode file paths or values
- Ignore IDE compatibility requirements

By avoiding these structural mistakes, you'll create prompts that work reliably, produce consistent results, and remain maintainable as your project evolves.

---

# üìö References

## Implementation Guidance

For repository-specific implementation rules, see:

- [.github/instructions/prompts.instructions.md](../../.github/instructions/prompts.instructions.md) - Prompt creation guidelines
- [.copilot/context/00.00-prompt-engineering/01-context-engineering-principles.md](../../.copilot/context/00.00-prompt-engineering/01-context-engineering-principles.md) - Core context engineering principles
- [.copilot/context/00.00-prompt-engineering/02-tool-composition-guide.md](../../.copilot/context/00.00-prompt-engineering/02-tool-composition-guide.md) - Tool selection patterns
- [.copilot/context/00.00-prompt-engineering/05-validation-caching-pattern.md](../../.copilot/context/00.00-prompt-engineering/05-validation-caching-pattern.md) - Validation caching for prompts

## Official GitHub Copilot Documentation

- **[GitHub Copilot Prompt Engineering Guide](https://docs.github.com/en/copilot/using-github-copilot/prompt-engineering-for-github-copilot)** `[üìò Official]`  
  *This comprehensive guide from GitHub provides foundational strategies for crafting effective prompts when working with GitHub Copilot. It covers general prompt engineering principles that apply across different Copilot interfaces and is essential reading for understanding how to communicate effectively with the AI assistant.*

- **[Customize Chat Responses and Set Context (Visual Studio)](https://learn.microsoft.com/en-us/visualstudio/ide/copilot-chat-context?view=visualstudio)** `[üìò Official]`  
  *The official Visual Studio documentation explains how to create and use `.prompt.md` files, custom instructions, and targeted `.instructions.md` files in your workspace. This reference details the YAML frontmatter options, file locations, and prompt invocation syntax for Visual Studio.*

- **[GitHub Copilot in Visual Studio](https://learn.microsoft.com/en-us/visualstudio/ide/visual-studio-github-copilot-extension)** `[üìò Official]`  
  *Microsoft's documentation for GitHub Copilot in Visual Studio provides specific information about prompt file support (available from version 17.10+) and explains the differences in functionality between Visual Studio and VS Code, which is crucial for understanding the environment-specific considerations discussed in this article.*

## Prompt Engineering Best Practices

- **[OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)** `[üìò Official]`  
  *While this guide is focused on OpenAI's models, the prompt engineering principles it discusses (clarity, specificity, providing examples, and iterative refinement) are universally applicable to GitHub Copilot. This reference helps readers understand the underlying LLM behavior that makes structured prompts effective.*

- **[Anthropic's Prompt Engineering Tutorial](https://docs.claude.com/en/docs/prompt-engineering)** `[üìò Official]`  
  *This tutorial offers insights into how large language models interpret instructions, including the importance of clear role definition, structured formatting, and providing context‚Äîall concepts that directly support the best practices outlined in this article for creating effective prompt files.*

## VS Code Release Notes

- **[VS Code v1.107 Release Notes](https://code.visualstudio.com/updates/v1_107)** `[üìò Official]`  
  *December 2024 release introducing Agent HQ unified interface, background agents with work tree isolation, MCP 1.0 features (Tasks, Sampling, Elicitation), GitHub MCP Server (Preview), enhanced Language Models Editor with BYOK support, and Claude skills integration. Relevant for understanding how prompts integrate with agent delegation workflows and new MCP tool capabilities.*

- **[VS Code MCP Servers Documentation](https://code.visualstudio.com/docs/copilot/customization/mcp-servers)** `[üìò Official]`  
  *Official documentation for configuring and using Model Context Protocol (MCP) servers in VS Code. Explains setup, toolsets, and integration patterns for MCP 1.0 features including the GitHub MCP Server (Preview).*

## Community Resources and Examples

- **[Microsoft AI Prompt Book for Architects](https://github.com/microsoft-partner-solutions-ai/ai-prompt-book)** `[üìò Official]`  
  *A curated collection of production-ready prompts organized by solution development lifecycle stages (Discovery, Rapid Prototyping, Delivery). This repository demonstrates the three-part prompt architecture (System Message, User Prompt Template, Example Usage) discussed in this article and provides concrete examples of prompts for requirements gathering, code scaffolding, architecture design, and more. Essential reference for understanding enterprise-grade prompt structuring.*

- **[GitHub Awesome Copilot Repository](https://github.com/github/awesome-copilot)** `[üìò Official]`  
  *GitHub's official curated list of resources, instruction examples, and prompt patterns for GitHub Copilot. This repository provides real-world examples and best practices for custom instructions files that complement the guidance in this article.*

## Related Articles in This Series

- **[How GitHub Copilot Uses Markdown and Prompt Folders](./02-getting-started/01.00-how_github_copilot_uses_markdown_and_prompt_folders.md)**  
  *Foundational article explaining the file locations and basic structure of prompts, agents, and instructions. Read this first to understand where files should be stored and how Copilot discovers them.*

- **[How to Name and Organize Prompt Files](./02.00-how_to_name_and_organize_prompt_files.md)**  
  *Best practices for organizing GitHub Copilot files in your repository, including naming conventions, folder structure, and the distinction between workspace and user-scope files.*

- **[How to Structure Content for Copilot Agent Files](./04.00-how_to_structure_content_for_copilot_agent_files.md)**  
  *Comprehensive guide to creating custom agents with `.agent.md` files. Learn how to design agent personas, configure tools, create handoff workflows, and understand how agents interact with prompts and instructions.*

- **[How to Optimize Prompts for Specific Models](./08.00-how_to_optimize_prompts_for_specific_models.md)**  
  *In-depth guide to tailoring prompts for different LLM families (GPT, Claude, Gemini). Covers model-specific syntax, reasoning model strategies, and multi-model architecture patterns for production systems.*

---

# Appendix A: YAML Frontmatter Metadata Reference

This appendix provides comprehensive documentation of all metadata fields supported in `.prompt.md` YAML frontmatter across GitHub Copilot implementations and related tools.

- **Core Metadata Fields** - Complete specifications for the 6 essential YAML fields:
  - `name` - Command identifier for invoking prompts
  - `description` - UI display text shown in prompt picker
  - `agent` - Execution mode (`ask`, `edit`, `agent`, or custom)
  - `model` - LLM selection for specific capabilities
  - `tools` - Capability restrictions for security/focus
  - `argument-hint` - Usage guidance displayed to users

- **Extended Metadata Fields** - Experimental and custom fields for advanced use cases:
  - `version`, `author`, `tags`, `category` for organization and tracking

- **Custom Agent Metadata** - Additional fields for `.agent.md` files defining specialized personas

- **Platform-Specific Differences** - Distinctions between VS Code and Visual Studio implementations

- **Complete Examples** - Full YAML headers showing all fields working together

- **Validation & Best Practices** - Essential guidance including:
  - Required vs optional fields checklist
  - Common mistakes and how to avoid them
  - Recommended configurations for different scenarios

- **Future Proposed Fields** - Community-requested capabilities planned for future releases

Each field entry includes: **type**, **support status**, **purpose**, **code examples**, and **best practices**. Use this appendix as your go-to reference when authoring or troubleshooting prompt files.

## Core Metadata Fields

### `name`
- **Type**: String
- **Required**: No (defaults to filename without extension)
- **Purpose**: Defines the command name used to invoke the prompt
- **VS Code**: Invoked as `/name` (slash command)
- **Visual Studio**: Invoked as `#name` (hashtag command)
- **Example**: `name: react-form` ‚Üí Use `/react-form` in VS Code
- **Best Practice**: Use lowercase with hyphens for multi-word names

```yaml
name: code-review
```

### `description`
- **Type**: String
- **Required**: No (but highly recommended)
- **Purpose**: Human-readable explanation shown in prompt picker/autocomplete
- **Visibility**: Appears in UI when selecting prompts
- **Character Limit**: Keep under 100 characters for best display
- **Best Practice**: Write clear, action-oriented descriptions

```yaml
description: "Review code for security vulnerabilities and best practices"
```

### `agent`
- **Type**: String (enum)
- **Required**: No (defaults to user's current chat mode)
- **Purpose**: Specifies the execution mode for the prompt
- **Supported Values**:
  - `ask` - Research/analysis mode (no file edits)
  - `edit` - Direct file modification mode
  - `agent` - Autonomous multi-step agent mode
  - Custom agent names (if `.agent.md` files defined)
- **VS Code**: Fully supported (1.106+)
- **Visual Studio**: Limited support (check version docs)

```yaml
agent: agent  # Use autonomous agent mode
```

**Agent Mode Comparison:**

| Mode | File Edits | Multi-step | Tool Access | Best For |
|------|------------|------------|-------------|----------|
| `ask` | No | Limited | Yes | Analysis, Q&A, research |
| `edit` | Yes | No | Limited | Direct code modifications |
| `agent` | Yes | Yes | Full | Complex workflows, automation |

### `model`
- **Type**: String
- **Required**: No (uses user's default model)
- **Purpose**: Specifies which LLM to use for this prompt
- **Common Values**:
  - `gpt-4` or `GPT-4`
  - `gpt-4-turbo`
  - `gpt-3.5-turbo`
  - `claude-sonnet-4.5`
  - `o1-preview`
  - `o3`
- **Availability**: Depends on user's Copilot subscription and enabled models
- **Best Practice**: Only specify when prompt requires specific model capabilities

```yaml
model: claude-sonnet-4.5  # Use Claude for this prompt
```

### `tools`
- **Type**: Array of strings
- **Required**: No (all tools available by default)
- **Purpose**: Restricts which tools/capabilities the prompt can use
- **Supported Values**:
  - `codebase` - Semantic search across repository
  - `editor` - File read/write operations
  - `filesystem` - Directory listing, file operations
  - `fetch` - Web content retrieval
  - `web_search` - Internet search capabilities
  - MCP server names (e.g., `github`, `azure`)
- **Use Case**: Security, performance, or focus constraints
- **VS Code**: Full support
- **Visual Studio**: Limited support

```yaml
tools: ['codebase', 'editor', 'filesystem']  # Restrict to local operations only
```

**Tool Access Patterns:**

```yaml
# Minimal tools (fast, focused)
tools: ['editor']

# Code-focused (no external access)
tools: ['codebase', 'editor', 'filesystem']

# Research-enabled (includes external data)
tools: ['codebase', 'fetch', 'web_search']

# Full access (all available tools)
tools: []  # or omit the field entirely
```

### `argument-hint`
- **Type**: String
- **Required**: No
- **Purpose**: Shows usage hint in chat input field
- **Visibility**: Displayed as placeholder text when invoking prompt
- **Best Practice**: Use concise syntax examples
- **Format**: Suggest argument patterns users should provide

```yaml
argument-hint: 'fields=name:string,age:number,email:string'
```

**Effective Argument Hints:**

```yaml
# File path argument
argument-hint: 'path/to/file.ts'

# Key-value pairs
argument-hint: 'component=Button props=variant,size'

# Optional parameters
argument-hint: '[language] [framework]'

# Multiple files
argument-hint: 'file1.ts file2.ts ...'
```

## Extended Metadata Fields

### `version`
- **Type**: String (semantic version)
- **Status**: Not officially documented but supported by some tools
- **Purpose**: Track prompt file versions for compatibility
- **Format**: Follow semantic versioning (major.minor.patch)

```yaml
version: "1.2.0"
```

### `author`
- **Type**: String or array
- **Status**: Not officially documented
- **Purpose**: Document prompt creator(s)
- **Use Case**: Team attribution, maintenance responsibility

```yaml
author: "Development Team"
# or
author: ["Alice Smith", "Bob Jones"]
```

### `tags`
- **Type**: Array of strings
- **Status**: Experimental/custom
- **Purpose**: Categorize prompts for searching/filtering
- **Use Case**: Large prompt libraries with organizational needs

```yaml
tags: ['security', 'code-review', 'python']
```

### `category`
- **Type**: String
- **Status**: Custom/organizational
- **Purpose**: High-level prompt classification
- **Use Case**: Aligns with prompt organization structure

```yaml
category: "quality-assurance"
```

## Custom Agent Metadata (`.agent.md` files)

When defining custom agents in `.github/agents/*.agent.md`, additional fields are available:

### `instructions`
- **Type**: Markdown content (in body, not YAML)
- **Purpose**: Define agent's system instructions and behavior
- **Location**: Main content after YAML frontmatter

### `functions` (Proposed)
- **Type**: Array of function definitions
- **Status**: Experimental
- **Purpose**: Define custom capabilities for specialized agents

## Platform-Specific Metadata

### VS Code Specific

```yaml
# VS Code Preview features (1.106+)
name: my-prompt
agent: custom-agent-name  # Reference .agent.md file
tools: ['codebase', '@mcp-server-name']  # MCP server integration
```

### Visual Studio Specific

```yaml
# Visual Studio 17.10+
name: my-prompt  # Invoked as #my-prompt (not /my-prompt)
# Note: Limited tool/agent support compared to VS Code
```

## Complete Example with All Common Fields

```yaml
---
name: comprehensive-code-review
description: "Perform security audit and best practices review with detailed report"
agent: agent
model: claude-sonnet-4.5
tools: ['codebase', 'editor', 'fetch']
argument-hint: '[focus=security|performance|style]'
version: "2.1.0"
author: "Security Team"
tags: ['security', 'code-review', 'audit']
category: "quality-assurance"
---

# Comprehensive Code Review Prompt

[Prompt content here...]
```

## Validation and Best Practices

**Required Fields Checklist:**
- ‚úÖ `name` (or rely on filename)
- ‚úÖ `description` (strongly recommended)

**Optional but Recommended:**
- `agent` - Specify if prompt needs specific mode
- `model` - Specify if prompt requires specific capabilities
- `tools` - Restrict for security/performance
- `argument-hint` - Guide users on usage

**Common Mistakes:**
- ‚ùå Using spaces in `name` (use hyphens: `code-review` not `code review`)
- ‚ùå Overly long `description` (keep under 100 chars)
- ‚ùå Specifying unavailable models (check user's subscription)
- ‚ùå Over-restricting tools (limits functionality unnecessarily)
- ‚ùå Vague argument hints (be specific about expected format)

## Future Metadata Fields (Proposed)

Based on community requests and tool evolution:

```yaml
# Proposed future fields
requires: ['extension-id']  # Extension dependencies
min-version: "1.95.0"       # Minimum VS Code version
max-tokens: 8000            # Token limit for responses
temperature: 0.7            # Model temperature override
context-files: ['docs/**']   # Auto-include file patterns
```

These fields are not currently supported but represent potential future capabilities.

---

# Appendix B: Tools and Capabilities Reference

Tools are capabilities that prompts can use to gather information, interact with code, access external resources, and perform operations. The `tools` YAML field controls which capabilities are available to a specific prompt, enabling fine-grained control over prompt behavior for security, performance, or focus reasons.

This appendix provides comprehensive documentation of all tools that can be specified in the `tools` YAML field, their capabilities, use cases, and access patterns.

**Core Built-in Tools:**
- **<mark>`codebase`</mark>** - Semantic search across workspace for code patterns, symbols, and implementations
- **<mark>`editor`</mark>** - File read/write operations including creating, modifying, and deleting files
- **<mark>`filesystem`</mark>** - Directory navigation, file queries, and metadata access (read-only)
- **<mark>`fetch`</mark>** - Retrieve content from web URLs and REST APIs
- **<mark>`web_search`</mark>** - Search the internet for current information and documentation

**MCP (Model Context Protocol) Server Tools:**
- **<mark>`@github`</mark>** - GitHub API integration for repository data, issues, and pull requests
- **<mark>`@azure`</mark>** - Azure resource management, queries, and documentation access
- **<mark>Custom servers</mark>** - Organization-specific tools (e.g., `@company-wiki`, `@internal-api-docs`)

**Common Tool Combinations:**
- **Local only**: `['codebase', 'editor', 'filesystem']` - No external network access
- **Research-enabled**: `['codebase', 'editor', 'fetch', 'web_search']` - Includes external resources
- **Full access**: `[]` or omit field - All available tools enabled

## Core Built-in Tools

### `codebase`
- **Purpose**: Semantic search across the entire workspace/repository
- **Capabilities**:
  - Search for code patterns, functions, classes, and symbols
  - Find related code implementations
  - Locate definitions and references
  - Understand project structure and relationships
- **Use Cases**:
  - Code review prompts needing context from multiple files
  - Refactoring operations requiring cross-file analysis
  - Documentation generation from existing code
  - Finding similar patterns or implementations
- **Performance**: Moderate (indexes workspace on first use)
- **Security**: Low risk (read-only access to workspace)

```yaml
tools: ['codebase']  # Enable semantic code search
```

**Example Query Patterns:**
- "Find all implementations of the UserService interface"
- "Locate error handling patterns in this project"
- "Search for security vulnerabilities in authentication code"

### `editor`
- **Purpose**: File read/write operations
- **Capabilities**:
  - Read file contents
  - Create new files
  - Modify existing files
  - Delete files
  - Rename/move files
- **Use Cases**:
  - Code generation prompts that create new files
  - Refactoring prompts that modify multiple files
  - Scaffolding prompts that build project structures
- **Performance**: Fast (direct file system operations)
- **Security**: Moderate risk (can modify workspace files)

```yaml
tools: ['editor']  # Enable file operations
```

**Best Practices:**
- Always preview changes before applying
- Use with `agent` mode for multi-file operations
- Combine with `codebase` for context-aware edits

### `filesystem`
- **Purpose**: Directory navigation and file system queries
- **Capabilities**:
  - List directory contents
  - Check file/directory existence
  - Get file metadata (size, modified date)
  - Traverse directory structures
  - Search for files by pattern
- **Use Cases**:
  - Project structure analysis
  - Finding configuration files
  - Discovering test files
  - Validating project setup
- **Performance**: Fast (file system queries)
- **Security**: Low risk (read-only operations)

```yaml
tools: ['filesystem']  # Enable directory operations
```

**Example Operations:**
- List all `.json` config files
- Find test files matching pattern `*.test.ts`
- Check if `.env` file exists
- Get workspace folder structure

### `fetch`
- **Purpose**: Retrieve content from web URLs
- **Capabilities**:
  - Download web pages
  - Access REST APIs
  - Retrieve documentation from URLs
  - Fetch external resources
- **Use Cases**:
  - Documentation research prompts
  - API integration verification
  - External resource validation
  - Pulling in reference materials
- **Performance**: Variable (depends on network and remote server)
- **Security**: Moderate risk (external network access)

```yaml
tools: ['fetch']  # Enable web content retrieval
```

**Supported Protocols:**
- `https://` (recommended)
- `http://` (use with caution)

**Limitations:**
- May be rate-limited by remote servers
- Authentication not supported for private APIs
- Subject to CORS and other web restrictions

### `web_search`
- **Purpose**: Search the internet for information
- **Capabilities**:
  - Find current information online
  - Locate documentation and tutorials
  - Research best practices
  - Discover recent developments
- **Use Cases**:
  - Research prompts needing latest information
  - Finding solutions to errors or issues
  - Discovering new libraries or tools
  - Validating current best practices
- **Performance**: Variable (depends on search provider)
- **Security**: Moderate risk (external network access)

```yaml
tools: ['web_search']  # Enable internet search
```

**Best Practices:**
- Use for information not available in workspace
- Verify results from authoritative sources
- Consider that results may change over time

## MCP (Model Context Protocol) Server Tools

MCP servers extend GitHub Copilot with additional capabilities through standardized protocols. Reference MCP tools using <mark>`@server-name`</mark> notation.

### Built-in MCP Servers

#### `@github`
- **Purpose**: GitHub API integration
- **Capabilities**:
  - Access repository information
  - Read issues and pull requests
  - Get commit history
  - Query GitHub metadata
- **Availability**: VS Code with GitHub Copilot extension

```yaml
tools: ['codebase', '@github']
```

**GitHub MCP Server (Preview - v1.107+):**  
VS Code 1.107 introduced a built-in GitHub remote MCP server that reuses existing GitHub authentication:
- Enable with: `github.copilot.chat.githubMcpServer.enabled: true`
- Configure toolsets: `github.copilot.chat.githubMcpServer.toolsets`
- Force read-only: `github.copilot.chat.githubMcpServer.readonly`
- Enterprise (GHE.com) support included

#### `@azure`
- **Purpose**: Azure resource management and queries
- **Capabilities**:
  - List Azure resources
  - Query resource properties
  - Access Azure documentation
  - Azure service integration
- **Availability**: With Azure GitHub Copilot extension

```yaml
tools: ['codebase', '@azure']
```

### Custom MCP Servers

Organizations can create custom MCP servers for proprietary tools and services:

```yaml
tools: ['codebase', '@company-wiki', '@internal-api-docs']
```

**Configuration**: Custom MCP servers must be registered in VS Code settings or workspace configuration.

## Tool Access Patterns

### Minimal Access (Fast, Focused)
Best for simple, targeted operations with no external dependencies.

```yaml
tools: ['editor']
```

**Use Cases:**
- Simple file edits
- Code formatting
- Comment generation

### Local Workspace Access (Code-Focused)
Enables comprehensive workspace analysis without external network access.

```yaml
tools: ['codebase', 'editor', 'filesystem']
```

**Use Cases:**
- Refactoring operations
- Project-wide code analysis
- Internal documentation generation
- Cross-file consistency checks

### Research-Enabled (External Resources)
Allows access to external information while maintaining workspace capabilities.

```yaml
tools: ['codebase', 'editor', 'fetch', 'web_search']
```

**Use Cases:**
- Documentation research
- API integration
- Best practices lookup
- Technology evaluation

### Full Access (All Capabilities)
Provides complete tool access for complex, autonomous operations.

```yaml
tools: []  # or omit the field entirely
# Enables all available tools by default
```

**Use Cases:**
- Complex agent workflows
- Multi-source research tasks
- Comprehensive code generation
- Advanced automation

## Tool Combinations by Use Case

### Code Review Prompt
```yaml
tools: ['codebase', 'filesystem', 'fetch']
```
- Search code for patterns (`codebase`)
- Find related test files (`filesystem`)
- Check external coding standards (`fetch`)

### Documentation Generator
```yaml
tools: ['codebase', 'editor', 'filesystem', 'web_search']
```
- Analyze code structure (`codebase`)
- Create documentation files (`editor`)
- Discover existing docs (`filesystem`)
- Research API documentation formats (`web_search`)

### Scaffolding Prompt
```yaml
tools: ['editor', 'filesystem', 'fetch']
```
- Create project files (`editor`)
- Check for existing structure (`filesystem`)
- Download templates/boilerplates (`fetch`)

### Security Audit Prompt
```yaml
tools: ['codebase', 'filesystem', 'web_search']
```
- Search for security patterns (`codebase`)
- Find configuration files (`filesystem`)
- Look up CVEs and vulnerabilities (`web_search`)

## Tool Restrictions and Security

### Why Restrict Tools?

1. **Security**: Limit external network access
2. **Performance**: Reduce tool overhead for simple tasks
3. **Focus**: Prevent prompt from using irrelevant capabilities
4. **Cost**: Some tools may have usage costs or limits

### Security Considerations by Tool

| Tool | Risk Level | Considerations |
|------|------------|----------------|
| `<codebase>` | Low | Read-only workspace access |
| `<editor>` | Moderate | Can modify files; review changes |
| `<filesystem>` | Low | Read-only; limited metadata access |
| `<fetch>` | Moderate | External network; validate URLs |
| `<web_search>` | Moderate | External network; results may vary |
| MCP Servers | Variable | Depends on server implementation |

### Recommended Restrictions

**Public/Shared Prompts:**
```yaml
tools: ['codebase', 'editor', 'filesystem']  # No external access
```

**Enterprise/Internal Prompts:**
```yaml
tools: ['codebase', 'editor', 'filesystem', '@internal-docs']
```

**Research-Heavy Prompts:**
```yaml
tools: ['codebase', 'fetch', 'web_search']  # External research OK
```

## Tool Availability by Platform

| Tool | VS Code 1.106+ | Visual Studio 17.10+ | Notes |
|------|----------------|----------------------|-------|
| `codebase` | ‚úÖ Full support | ‚úÖ Full support | Core functionality |
| `editor` | ‚úÖ Full support | ‚úÖ Full support | Core functionality |
| `filesystem` | ‚úÖ Full support | ‚úÖ Full support | Core functionality |
| `fetch` | ‚úÖ Full support | ‚ö†Ô∏è Limited | Check version docs |
| `web_search` | ‚úÖ Full support | ‚ö†Ô∏è Limited | May require settings |
| `@github` | ‚úÖ With extension | ‚ùå Not supported | VS Code only |
| `@azure` | ‚úÖ With extension | ‚ö†Ô∏è Different impl. | Platform-specific |
| Custom MCP | ‚úÖ Preview feature | ‚ùå Not supported | VS Code 1.106+ |

## Tool Usage Best Practices

### Start Minimal, Expand as Needed
```yaml
# Start with minimal tools
tools: ['editor']

# Add tools only when required
tools: ['codebase', 'editor']  # Added codebase for context

# Enable research when needed
tools: ['codebase', 'editor', 'fetch']  # Added fetch for docs
```

### Explicit is Better Than Implicit
```yaml
# ‚ùå Unclear intent
tools: []  # All tools enabled

# ‚úÖ Clear intent
tools: ['codebase', 'editor', 'filesystem']  # Local operations only
```

### Document Tool Requirements
```yaml
---
name: security-audit
tools: ['codebase', 'filesystem', 'web_search']
description: "Audit code for vulnerabilities (requires internet for CVE lookup)"
---

# Security Audit Prompt

**Required Tools:**
- `codebase`: Search code for security patterns
- `filesystem`: Find configuration files
- `web_search`: Look up CVEs and best practices
```

### Test with Restricted Tools
Before deploying prompts, test with restricted tool access to ensure graceful handling of missing capabilities:

```yaml
# Development version
tools: ['codebase', 'editor', 'fetch', 'web_search']

# Production version (more restrictive)
tools: ['codebase', 'editor']
```

## Future Tool Capabilities (Proposed)

Based on community feedback and tool evolution:

```yaml
# Proposed future tools
tools: [
  'codebase',
  'editor',
  'terminal',        # Execute commands
  'debugger',        # Debugging integration
  'git',             # Version control operations
  'package-manager', # npm/pip/maven operations
  'database',        # Database queries
  'cloud-provider'   # Cloud resource management
]
```

These tools are not currently supported but represent potential future extensions to the GitHub Copilot tools ecosystem.

---

<!-- 
---
validations:
  consistency_review:
    status: "completed"
    last_run: "2025-12-07T00:00:00Z"
    model: "claude-sonnet-4.5"
    references_checked: 8
    references_valid: 6
    references_broken: 2
    references_updated: 2
    gaps_identified: 3
    gaps_addressed: 3
    changes_summary: "Fixed broken reference URLs (VS Code custom prompts, Anthropic docs); Added .instructions.md files documentation; Enhanced Visual Studio prompt invocation syntax; Added reference classification markers; Removed broken community links"
article_metadata:
  filename: "03.00-how_to_structure_content_for_copilot_prompt_files.md"
  last_updated: "2025-12-24T00:00:00Z"
  version_history:
    - date: "2025-12-24"
      changes: "Added v1.107 features: GitHub MCP Server preview, release notes references, MCP 1.0 documentation"
    - date: "2025-12-07"
      changes: "Consistency and gap review - Updated references, added .instructions.md coverage, enhanced VS-specific guidance"
---
-->
